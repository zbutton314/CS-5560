{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KDM_ICP4.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqjcwzS24Jr_"
      },
      "source": [
        "Setting up PySpark in Colab\n",
        "\n",
        "Spark is written in the Scala programming language and requires the Java Virtual Machine (JVM) to run. Therefore, our first task is to download Java"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iGswToj4LIS",
        "outputId": "9365a1cc-47a6-42c3-d0f2-fcc66834c035"
      },
      "source": [
        "!sudo apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.142)] [Connecting to security.u\r0% [Connecting to archive.ubuntu.com (91.189.88.142)] [Connecting to security.u\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.142)\r                                                                               \rGet:2 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [2 In\r                                                                               \rGet:3 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [3 InRelease 14.2 kB/88.7 k\r                                                                               \rHit:4 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:6 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Ign:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:9 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:10 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Ign:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [696 B]\n",
            "Hit:13 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:14 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:15 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,825 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,564 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,004 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [21.1 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,468 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [783 kB]\n",
            "Get:21 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [935 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,247 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [816 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [29.0 kB]\n",
            "Get:25 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [42.8 kB]\n",
            "Get:27 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [917 kB]\n",
            "Fetched 14.9 MB in 5s (3,135 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzRtNPkq5VIR"
      },
      "source": [
        "Next, we will install Apache Spark 3.0.1 with Hadoop 2.7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBYZfbpk34H3"
      },
      "source": [
        "!wget -q https://downloads.apache.org/spark/spark-3.0.3/spark-3.0.3-bin-hadoop3.2.tgz\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4L21HeCi5bde"
      },
      "source": [
        "Now, we just need to unzip that folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-D2QoWK5cEg"
      },
      "source": [
        "!tar xf spark-3.0.3-bin-hadoop3.2.tgz"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grIssZqC8aYj"
      },
      "source": [
        "There is one last thing that we need to install and that is the findspark library. It will locate Spark on the system and import it as a regular library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wke-MaxX57M9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e200295-6f45-48a1-bf0a-f4f59de342ae"
      },
      "source": [
        "!pip install -q findspark\n",
        "!pip install pyspark==3.0.2"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark==3.0.2\n",
            "  Downloading pyspark-3.0.2.tar.gz (204.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 204.8 MB 49 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 40.3 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.0.2-py2.py3-none-any.whl size=205186690 sha256=4dd6ea300f9ce515b47096ea679721550b4f9807aa178b32dbce656a31e4f22e\n",
            "  Stored in directory: /root/.cache/pip/wheels/9a/39/f6/970565f38054a830e9a8593f388b36e14d75dba6c6fdafc1ec\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AJ1RV578hE9"
      },
      "source": [
        "Now that we have installed all the necessary dependencies in Colab, it is time to set the environment path. This will enable us to run Pyspark in the Colab environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvMEW0ol59ts"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] =  \"/content/spark-3.0.3-bin-hadoop3.2\""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weGRBVLK8nKb"
      },
      "source": [
        "We need to locate Spark in the system. For that, we import findspark and use the findspark.init() method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSleoMKz6Ecg"
      },
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6gW5avs8yWa"
      },
      "source": [
        "If you want to know the location where Spark is installed, use findspark.find()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "a3EHL6x76KcK",
        "outputId": "5a68b630-d1ec-4e85-e6a2-ac9d63dd628e"
      },
      "source": [
        "findspark.find()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/usr/local/lib/python3.7/dist-packages/pyspark'"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sI0EI6Ox87wT"
      },
      "source": [
        "Now, we can import SparkSession from pyspark.sql and create a SparkSession, which is the entry point to Spark.\n",
        "\n",
        "You can give a name to the session using appName() and add some configurations with config() if you wish."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcGOvWMJ6PUo"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder\\\n",
        "        .master(\"local\")\\\n",
        "        .appName(\"Colab\")\\\n",
        "        .config('spark.ui.port', '4050')\\\n",
        "        .getOrCreate()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djWQ29kL9Ogy"
      },
      "source": [
        "Finally, print the SparkSession variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "GvcENqE16XEj",
        "outputId": "b1607354-11c2-456c-d7bb-c3b714fdf781"
      },
      "source": [
        "spark"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://37417341b839:4050\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.0.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Colab</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f34a87fed50>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4btlV8p6b3Q",
        "outputId": "f7db7f3f-3e14-4ca6-eecc-0f1cbc342bcf"
      },
      "source": [
        "#we need to load the dataset. We will use the read.csv module. \n",
        "#The inferSchema parameter provided will enable Spark to automatically determine the data type for each column but it has to go over the data once.\n",
        "# If you don’t want that to happen, then you can instead provide the schema explicitly in the schema parameter.\n",
        "\n",
        "df = spark.read.csv(\"/content/data.csv\", header=True, inferSchema= True)\n",
        "df.printSchema()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- customerID: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- SeniorCitizen: integer (nullable = true)\n",
            " |-- Partner: string (nullable = true)\n",
            " |-- Dependents: string (nullable = true)\n",
            " |-- tenure: integer (nullable = true)\n",
            " |-- PhoneService: string (nullable = true)\n",
            " |-- MultipleLines: string (nullable = true)\n",
            " |-- InternetService: string (nullable = true)\n",
            " |-- OnlineSecurity: string (nullable = true)\n",
            " |-- OnlineBackup: string (nullable = true)\n",
            " |-- DeviceProtection: string (nullable = true)\n",
            " |-- TechSupport: string (nullable = true)\n",
            " |-- StreamingTV: string (nullable = true)\n",
            " |-- StreamingMovies: string (nullable = true)\n",
            " |-- Contract: string (nullable = true)\n",
            " |-- PaperlessBilling: string (nullable = true)\n",
            " |-- PaymentMethod: string (nullable = true)\n",
            " |-- MonthlyCharges: double (nullable = true)\n",
            " |-- TotalCharges: string (nullable = true)\n",
            " |-- Churn: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0U-Tk7V7NC5",
        "outputId": "3af375e1-2514-46d4-f4f9-5bf5953322c6"
      },
      "source": [
        "df.show(5, truncate=False)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------+-------------+-------+----------+------+------------+----------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+-------------------------+--------------+------------+-----+\n",
            "|customerID|gender|SeniorCitizen|Partner|Dependents|tenure|PhoneService|MultipleLines   |InternetService|OnlineSecurity|OnlineBackup|DeviceProtection|TechSupport|StreamingTV|StreamingMovies|Contract      |PaperlessBilling|PaymentMethod            |MonthlyCharges|TotalCharges|Churn|\n",
            "+----------+------+-------------+-------+----------+------+------------+----------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+-------------------------+--------------+------------+-----+\n",
            "|7590-VHVEG|Female|0            |Yes    |No        |1     |No          |No phone service|DSL            |No            |Yes         |No              |No         |No         |No             |Month-to-month|Yes             |Electronic check         |29.85         |29.85       |No   |\n",
            "|5575-GNVDE|Male  |0            |No     |No        |34    |Yes         |No              |DSL            |Yes           |No          |Yes             |No         |No         |No             |One year      |No              |Mailed check             |56.95         |1889.5      |No   |\n",
            "|3668-QPYBK|Male  |0            |No     |No        |2     |Yes         |No              |DSL            |Yes           |Yes         |No              |No         |No         |No             |Month-to-month|Yes             |Mailed check             |53.85         |108.15      |Yes  |\n",
            "|7795-CFOCW|Male  |0            |No     |No        |45    |No          |No phone service|DSL            |Yes           |No          |Yes             |Yes        |No         |No             |One year      |No              |Bank transfer (automatic)|42.3          |1840.75     |No   |\n",
            "|9237-HQITU|Female|0            |No     |No        |2     |Yes         |No              |Fiber optic    |No            |No          |No              |No         |No         |No             |Month-to-month|Yes             |Electronic check         |70.7          |151.65      |Yes  |\n",
            "+----------+------+-------------+-------+----------+------+------------+----------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+-------------------------+--------------+------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZkvWbw97S7Y",
        "outputId": "c7463722-abc4-4621-95e5-0faa35a760e5"
      },
      "source": [
        "#If you didn't set inderShema to True, here is what is happening to the type. There are all in string.\n",
        "df_string = spark.read.csv(\"/content/data.csv\", header=True, inferSchema=  False)\n",
        "df_string.printSchema()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- customerID: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- SeniorCitizen: string (nullable = true)\n",
            " |-- Partner: string (nullable = true)\n",
            " |-- Dependents: string (nullable = true)\n",
            " |-- tenure: string (nullable = true)\n",
            " |-- PhoneService: string (nullable = true)\n",
            " |-- MultipleLines: string (nullable = true)\n",
            " |-- InternetService: string (nullable = true)\n",
            " |-- OnlineSecurity: string (nullable = true)\n",
            " |-- OnlineBackup: string (nullable = true)\n",
            " |-- DeviceProtection: string (nullable = true)\n",
            " |-- TechSupport: string (nullable = true)\n",
            " |-- StreamingTV: string (nullable = true)\n",
            " |-- StreamingMovies: string (nullable = true)\n",
            " |-- Contract: string (nullable = true)\n",
            " |-- PaperlessBilling: string (nullable = true)\n",
            " |-- PaymentMethod: string (nullable = true)\n",
            " |-- MonthlyCharges: string (nullable = true)\n",
            " |-- TotalCharges: string (nullable = true)\n",
            " |-- Churn: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mgfvQEo74_Y",
        "outputId": "7ee3a77f-65f7-4fd7-8fdb-b2b83caf8fcf"
      },
      "source": [
        "#You can select and show the rows with select and the names of the features. Below, gender and churn are selected.\n",
        "df.select('gender','churn').show(5)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+\n",
            "|gender|churn|\n",
            "+------+-----+\n",
            "|Female|   No|\n",
            "|  Male|   No|\n",
            "|  Male|  Yes|\n",
            "|  Male|   No|\n",
            "|Female|  Yes|\n",
            "+------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-aXM9_x8BIU",
        "outputId": "48187486-1548-4bda-bba2-60020c2109c5"
      },
      "source": [
        "#To get a summary statistics, of the data, you can use describe(). It will compute the :count, mean, standarddeviation, min, max\n",
        "df.describe().show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+------+------------------+-------+----------+------------------+------------+-------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+--------------------+------------------+------------------+-----+\n",
            "|summary|customerID|gender|     SeniorCitizen|Partner|Dependents|            tenure|PhoneService|MultipleLines|InternetService|OnlineSecurity|OnlineBackup|DeviceProtection|TechSupport|StreamingTV|StreamingMovies|      Contract|PaperlessBilling|       PaymentMethod|    MonthlyCharges|      TotalCharges|Churn|\n",
            "+-------+----------+------+------------------+-------+----------+------------------+------------+-------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+--------------------+------------------+------------------+-----+\n",
            "|  count|      7043|  7043|              7043|   7043|      7043|              7043|        7043|         7043|           7043|          7043|        7043|            7043|       7043|       7043|           7043|          7043|            7043|                7043|              7043|              7043| 7043|\n",
            "|   mean|      null|  null|0.1621468124378816|   null|      null| 32.37114865824223|        null|         null|           null|          null|        null|            null|       null|       null|           null|          null|            null|                null| 64.76169246059922|2283.3004408418697| null|\n",
            "| stddev|      null|  null|0.3686116056100135|   null|      null|24.559481023094442|        null|         null|           null|          null|        null|            null|       null|       null|           null|          null|            null|                null|30.090047097678482| 2266.771361883145| null|\n",
            "|    min|0002-ORFBO|Female|                 0|     No|        No|                 0|          No|           No|            DSL|            No|          No|              No|         No|         No|             No|Month-to-month|              No|Bank transfer (au...|             18.25|                  |   No|\n",
            "|    max|9995-HOTOH|  Male|                 1|    Yes|       Yes|                72|         Yes|          Yes|             No|           Yes|         Yes|             Yes|        Yes|        Yes|            Yes|      Two year|             Yes|        Mailed check|            118.75|             999.9|  Yes|\n",
            "+-------+----------+------+------------------+-------+----------+------------------+------------+-------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+--------------------+------------------+------------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccQW1Roy97p7",
        "outputId": "960c9151-3c04-4243-8315-f2c17e4b5ee4"
      },
      "source": [
        "#Distinct values for Categorical columns\n",
        "#The distinct() will come in handy when you want to determine the unique values in the categorical columns in the dataframe.\n",
        "\n",
        "df.select(\"PaymentMethod\").distinct().show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|       PaymentMethod|\n",
            "+--------------------+\n",
            "|Credit card (auto...|\n",
            "|        Mailed check|\n",
            "|Bank transfer (au...|\n",
            "|    Electronic check|\n",
            "+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zmVWSmOEqaB"
      },
      "source": [
        "Map reduce example:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qMnKKNQ-mPZ",
        "outputId": "4759307c-f0cc-467e-daac-25fc3a38a7c6"
      },
      "source": [
        "# For map reduce we need to create SparkContext so that we can read a textfile and perform mapping function on it. \n",
        "from pyspark import SparkContext\n",
        "sc = SparkContext.getOrCreate()\n",
        "text_file = sc.textFile(\"/content/icp4.txt\")\n",
        "counts = text_file.flatMap(lambda line: line.split(\" \")) \\\n",
        "             .map(lambda word: (word, 1)) \\\n",
        "             .reduceByKey(lambda a, b: a + b)\n",
        "for x in counts.collect():\n",
        "    print (x)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('People', 1)\n",
            "('who', 1)\n",
            "('have', 1)\n",
            "('been', 1)\n",
            "('fully', 1)\n",
            "('vaccinated', 1)\n",
            "('against', 1)\n",
            "('coronavirus', 1)\n",
            "('--', 2)\n",
            "('right', 1)\n",
            "('now', 1)\n",
            "('that', 1)\n",
            "('means', 1)\n",
            "('with', 2)\n",
            "('two', 1)\n",
            "('doses', 1)\n",
            "('of', 1)\n",
            "('either', 1)\n",
            "('the', 4)\n",
            "('Pfizer/BioNTech', 1)\n",
            "('or', 1)\n",
            "('Moderna', 1)\n",
            "('vaccine', 1)\n",
            "('can', 1)\n",
            "('skip', 1)\n",
            "('quarantine', 1)\n",
            "('if', 1)\n",
            "('they', 2)\n",
            "('are', 1)\n",
            "('exposed', 1)\n",
            "('to', 2)\n",
            "('someone', 1)\n",
            "('infected', 1)\n",
            "('virus,', 1)\n",
            "('US', 1)\n",
            "('Centers', 1)\n",
            "('for', 2)\n",
            "('Disease', 1)\n",
            "('Control', 1)\n",
            "('and', 1)\n",
            "('Prevention', 1)\n",
            "('said', 1)\n",
            "('Wednesday.That', 1)\n",
            "(\"doesn't\", 1)\n",
            "('mean', 1)\n",
            "('should', 1)\n",
            "('stop', 1)\n",
            "('taking', 1)\n",
            "('precautions,', 1)\n",
            "('CDC', 1)\n",
            "('noted', 1)\n",
            "('in', 1)\n",
            "('updated', 1)\n",
            "('guidance.', 1)\n",
            "(\"It's\", 1)\n",
            "('just', 1)\n",
            "('not', 1)\n",
            "('necessary', 1)\n",
            "('them', 1)\n",
            "('quarantine.', 1)\n"
          ]
        }
      ]
    }
  ]
}