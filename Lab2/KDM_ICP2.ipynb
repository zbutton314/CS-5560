{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KDM_ICP2 (1).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0e294fef3d984aedbdf69f69ec18ccf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c8eaaf68b56b43829223aacaee99f9eb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e33a0e3db4f346b29fe7348f7ddc84d5",
              "IPY_MODEL_a07530bf6f824f1ea6df6b7c8a1eb4e3",
              "IPY_MODEL_3956f6208c474bfaa2820801106ac5a5"
            ]
          }
        },
        "c8eaaf68b56b43829223aacaee99f9eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e33a0e3db4f346b29fe7348f7ddc84d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_60087576013241e4b90f048c6698d581",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading https://huggingface.co/stanfordnlp/CoreNLP/resolve/main/stanford-corenlp-latest.zip: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f08116a47e1d44edbdde00d2e63a5cb9"
          }
        },
        "a07530bf6f824f1ea6df6b7c8a1eb4e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_954af28a8c5640a5b451e407ef3f3817",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 505207915,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 505207915,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4b6285bf88474179b51c3e64422d2eb2"
          }
        },
        "3956f6208c474bfaa2820801106ac5a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_251d6a33db11490d916d6b1b8bdcecec",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 505M/505M [00:07&lt;00:00, 41.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_60cf127ed2604df9aa92eef1629185f4"
          }
        },
        "60087576013241e4b90f048c6698d581": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f08116a47e1d44edbdde00d2e63a5cb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "954af28a8c5640a5b451e407ef3f3817": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4b6285bf88474179b51c3e64422d2eb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "251d6a33db11490d916d6b1b8bdcecec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "60cf127ed2604df9aa92eef1629185f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dh8HjUuVdE9s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8d5be08-0043-4553-89c9-c253e742913a"
      },
      "source": [
        "# Install stanza, Installing and importing Stanza are as simple as running the following commands. \n",
        "!pip install stanza\n",
        "\n",
        "# Import stanza\n",
        "import stanza"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stanza\n",
            "  Downloading stanza-1.3.0-py3-none-any.whl (432 kB)\n",
            "\u001b[?25l\r\u001b[K     |▊                               | 10 kB 27.1 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20 kB 13.4 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 30 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |███                             | 40 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 51 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 61 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 71 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |██████                          | 81 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 92 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 102 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 112 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 122 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 133 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 143 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 153 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 163 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 174 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 184 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 194 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 204 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 215 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 225 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 235 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 245 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 256 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 266 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 276 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 286 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 296 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 307 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 317 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 327 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 337 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 348 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 358 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 368 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 378 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 389 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 399 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 409 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 419 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 430 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 432 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from stanza) (1.10.0+cu111)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from stanza) (3.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stanza) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from stanza) (4.62.3)\n",
            "Collecting emoji\n",
            "  Downloading emoji-1.6.3.tar.gz (174 kB)\n",
            "\u001b[K     |████████████████████████████████| 174 kB 46.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from stanza) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from stanza) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.0->stanza) (3.10.0.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (2021.10.8)\n",
            "Building wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.6.3-py3-none-any.whl size=170298 sha256=c9db8138520f64474f7c10f3de2df993ac7812aac1a1fa5954747d7b4d9e16b1\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/8b/d7/ad579fbef83c287215c0caab60fb0ae0f30c4d7ce5f580eade\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji, stanza\n",
            "Successfully installed emoji-1.6.3 stanza-1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwyQwpeYsFEj"
      },
      "source": [
        "Setting up Stanford CoreNLP\n",
        "\n",
        "In order for the interface to work, the Stanford CoreNLP library has to be installed and a CORENLP_HOME environment variable has to be pointed to the installation location.\n",
        "\n",
        "Here I am going to show you how to download and install the CoreNLP library on your machine, with Stanza's installation command:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "0e294fef3d984aedbdf69f69ec18ccf4",
            "c8eaaf68b56b43829223aacaee99f9eb",
            "e33a0e3db4f346b29fe7348f7ddc84d5",
            "a07530bf6f824f1ea6df6b7c8a1eb4e3",
            "3956f6208c474bfaa2820801106ac5a5",
            "60087576013241e4b90f048c6698d581",
            "f08116a47e1d44edbdde00d2e63a5cb9",
            "954af28a8c5640a5b451e407ef3f3817",
            "4b6285bf88474179b51c3e64422d2eb2",
            "251d6a33db11490d916d6b1b8bdcecec",
            "60cf127ed2604df9aa92eef1629185f4"
          ]
        },
        "id": "fNYFfu47dMDp",
        "outputId": "07feab52-f207-45e9-93d1-e28334f5b13d"
      },
      "source": [
        "# Download the Stanford CoreNLP package with Stanza's installation command\n",
        "# This'll take several minutes, depending on the network speed\n",
        "corenlp_dir = './corenlp'\n",
        "stanza.install_corenlp(dir=corenlp_dir)\n",
        "\n",
        "# Set the CORENLP_HOME environment variable to point to the installation location\n",
        "import os\n",
        "os.environ[\"CORENLP_HOME\"] = corenlp_dir"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-01-27 17:18:47 INFO: Installing CoreNLP package into ./corenlp...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0e294fef3d984aedbdf69f69ec18ccf4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading https://huggingface.co/stanfordnlp/CoreNLP/resolve/main/stanford-corenlp-latest.zip:   0%|        …"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-01-27 17:18:57 WARNING: For customized installation location, please set the `CORENLP_HOME` environment variable to the location of the installation. In Unix, this is done with `export CORENLP_HOME=./corenlp`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cExj-I4QsYNu"
      },
      "source": [
        "That's all for the installation!\n",
        "\n",
        "We can now double check if the installation is successful by listing files in the CoreNLP directory. \n",
        "\n",
        "You should be able to see a number of .jar files by running the following command:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4k0OSQX9dl6v",
        "outputId": "cf0a2428-2638-4f68-8a9b-20f8fe3e88b4"
      },
      "source": [
        "# Examine the CoreNLP installation folder to make sure the installation is successful\n",
        "!ls $CORENLP_HOME"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "build.xml\t\t\t\t  jollyday.jar\n",
            "corenlp.sh\t\t\t\t  LIBRARY-LICENSES\n",
            "CoreNLP-to-HTML.xsl\t\t\t  LICENSE.txt\n",
            "ejml-core-0.39.jar\t\t\t  Makefile\n",
            "ejml-core-0.39-sources.jar\t\t  patterns\n",
            "ejml-ddense-0.39.jar\t\t\t  pom-java-11.xml\n",
            "ejml-ddense-0.39-sources.jar\t\t  pom-java-17.xml\n",
            "ejml-simple-0.39.jar\t\t\t  pom.xml\n",
            "ejml-simple-0.39-sources.jar\t\t  protobuf-java-3.19.2.jar\n",
            "input.txt\t\t\t\t  README.txt\n",
            "input.txt.out\t\t\t\t  RESOURCE-LICENSES\n",
            "input.txt.xml\t\t\t\t  SemgrexDemo.java\n",
            "istack-commons-runtime-3.0.7.jar\t  ShiftReduceDemo.java\n",
            "istack-commons-runtime-3.0.7-sources.jar  slf4j-api.jar\n",
            "javax.activation-api-1.2.0.jar\t\t  slf4j-simple.jar\n",
            "javax.activation-api-1.2.0-sources.jar\t  stanford-corenlp-4.4.0.jar\n",
            "javax.json-api-1.0-sources.jar\t\t  stanford-corenlp-4.4.0-javadoc.jar\n",
            "javax.json.jar\t\t\t\t  stanford-corenlp-4.4.0-models.jar\n",
            "jaxb-api-2.4.0-b180830.0359.jar\t\t  stanford-corenlp-4.4.0-sources.jar\n",
            "jaxb-api-2.4.0-b180830.0359-sources.jar   StanfordCoreNlpDemo.java\n",
            "jaxb-impl-2.4.0-b180830.0438.jar\t  StanfordDependenciesManual.pdf\n",
            "jaxb-impl-2.4.0-b180830.0438-sources.jar  sutime\n",
            "joda-time-2.10.5-sources.jar\t\t  tokensregex\n",
            "joda-time.jar\t\t\t\t  xom-1.3.7-sources.jar\n",
            "jollyday-0.4.9-sources.jar\t\t  xom.jar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmp2gc4Gsm_Q"
      },
      "source": [
        "Constructing CoreNLPClient\n",
        "\n",
        "At a high level, the CoreNLP Python interface works by first starting a background Java CoreNLP server process, and then initializing a client instance in Python which can pass the text to the background server process, and accept the returned annotation results.\n",
        "\n",
        "We wrap these functionalities in a CoreNLPClient class. Therefore, we need to start by importing this class from Stanza."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQaXGcIidp8N"
      },
      "source": [
        "# Import client module\n",
        "from stanza.server import CoreNLPClient"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ly99wQ9sswl1"
      },
      "source": [
        "After the import is done, we can construct a CoreNLPClient instance. The constructor method takes a Python list of annotator names as argument. Here let's explore some basic annotators including tokenization, sentence split, part-of-speech tagging, lemmatization, named entity recognition (NER), parsing and Coreference resolution. \n",
        "\n",
        "Additionally, the client constructor accepts a memory argument, which specifies how much memory will be allocated to the background Java process. An endpoint option can be used to specify a port number used by the communication between the server and the client. The default port is 9000. However, since this port is pre-occupied by a system process in Colab, we'll manually set it to 9001 in the following example.\n",
        "\n",
        "Also, here we manually set be_quiet=True to avoid an IO issue in colab notebook. You should be able to use be_quiet=False on your own computer, which will print detailed logging information from CoreNLP during usage.\n",
        "\n",
        "For more options in constructing the clients, please refer to 'https://stanfordnlp.github.io/stanza/corenlp_client.html#corenlp-client-options'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXez1IpIdxYF",
        "outputId": "f285ba29-9806-494e-99e5-199d44dd4e47"
      },
      "source": [
        "# Construct a CoreNLPClient with some basic annotators, a memory allocation of 4GB, and port number 9001\n",
        "client = CoreNLPClient(\n",
        "    annotators=['tokenize','ssplit','pos','lemma','ner', 'parse', 'depparse','coref'], \n",
        "    memory='4G', \n",
        "    endpoint='http://localhost:9001',\n",
        "    be_quiet=True)\n",
        "print(client)\n",
        "\n",
        "# Start the background server and wait for some time\n",
        "# Note that in practice this is totally optional, as by default the server will be started when the first annotation is performed\n",
        "client.start()\n",
        "import time; time.sleep(10)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-01-27 17:19:15 INFO: Writing properties to tmp file: corenlp_server-422d6f085e7741f8.props\n",
            "2022-01-27 17:19:15 INFO: Starting server with command: java -Xmx4G -cp ./corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 60000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-422d6f085e7741f8.props -annotators tokenize,ssplit,pos,lemma,ner,parse,depparse,coref -preload -outputFormat serialized\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<stanza.server.client.CoreNLPClient object at 0x7efbfcd96fd0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huHe7t4NttN6"
      },
      "source": [
        "After the above code block finishes executing, if you print the background processes, you should be able to find the Java CoreNLP server running."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-6a5KoAd-H2",
        "outputId": "e0a1b179-75d5-4803-d2ed-fc3994080ca8"
      },
      "source": [
        "# Print background processes and look for java\n",
        "# You should be able to see a StanfordCoreNLPServer java process running in the background\n",
        "!ps -o pid,cmd | grep java"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    165 java -Xmx4G -cp ./corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 60000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-422d6f085e7741f8.props -annotators tokenize,ssplit,pos,lemma,ner,parse,depparse,coref -preload -outputFormat serialized\n",
            "    186 /bin/bash -c ps -o pid,cmd | grep java\n",
            "    188 grep java\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YgEdpIgtxt9"
      },
      "source": [
        "Annotating Text\n",
        "\n",
        "Annotating a piece of text is as simple as passing the text into an annotate function of the client object. After the annotation is complete, a Document object will be returned with all annotations.\n",
        "\n",
        "Note that although in general annotations are very fast, the first annotation might take a while to complete in the notebook. Please stay patient."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IT3DqBv-eDrl",
        "outputId": "a3784cf7-e7c6-4ac8-d9df-b01ef45fa9ba"
      },
      "source": [
        "# Annotate some text\n",
        "text = \"Albert Einstein was a German-born theoretical physicist. He developed the theory of relativity.\"\n",
        "document = client.annotate(text)\n",
        "print(type(document))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'CoreNLP_pb2.Document'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U43zcqcTuHV4"
      },
      "source": [
        "Accessing Annotations\n",
        "\n",
        "Annotations can be accessed from the returned Document object.\n",
        "\n",
        "A Document contains a list of Sentences, which contain a list of Tokens. Here let's first explore the annotations stored in all tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gLDG2Ihe6yr",
        "outputId": "b175aa33-c3be-4f40-90b2-9fd71ff51be3"
      },
      "source": [
        "print(\"{:12s}\\t{:12s}\\t{:6s}\\t{}\".format(\"Word\", \"Lemma\", \"POS\", \"NER\"))\n",
        "\n",
        "for i, sent in enumerate(document.sentence):\n",
        "    print(\"[Sentence {}]\".format(i+1))\n",
        "    for t in sent.token:\n",
        "        print(\"{:12s}\\t{:12s}\\t{:6s}\\t{}\".format(t.word, t.lemma, t.pos, t.ner))\n",
        "    print(\"\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word        \tLemma       \tPOS   \tNER\n",
            "[Sentence 1]\n",
            "Albert      \tAlbert      \tNNP   \tPERSON\n",
            "Einstein    \tEinstein    \tNNP   \tPERSON\n",
            "was         \tbe          \tVBD   \tO\n",
            "a           \ta           \tDT    \tO\n",
            "German      \tgerman      \tJJ    \tNATIONALITY\n",
            "-           \t-           \tHYPH  \tO\n",
            "born        \tbear        \tVBN   \tO\n",
            "theoretical \ttheoretical \tJJ    \tTITLE\n",
            "physicist   \tphysicist   \tNN    \tTITLE\n",
            ".           \t.           \t.     \tO\n",
            "\n",
            "[Sentence 2]\n",
            "He          \the          \tPRP   \tO\n",
            "developed   \tdevelop     \tVBD   \tO\n",
            "the         \tthe         \tDT    \tO\n",
            "theory      \ttheory      \tNN    \tO\n",
            "of          \tof          \tIN    \tO\n",
            "relativity  \trelativity  \tNN    \tO\n",
            ".           \t.           \t.     \tO\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzs40nFOurmP"
      },
      "source": [
        "Alternatively, you can also browse the NER results by iterating over entity mentions over the sentences. For example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-k16JaXWuL9U",
        "outputId": "d1e950cb-793d-46d7-e54f-4051b885b77a"
      },
      "source": [
        "# Iterate over all detected entity mentions\n",
        "print(\"{:30s}\\t{}\".format(\"Mention\", \"Type\"))\n",
        "\n",
        "for sent in document.sentence:\n",
        "    for m in sent.mentions:\n",
        "        print(\"{:30s}\\t{}\".format(m.entityMentionText, m.entityType))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mention                       \tType\n",
            "Albert Einstein               \tPERSON\n",
            "German                        \tNATIONALITY\n",
            "theoretical physicist         \tTITLE\n",
            "He                            \tPERSON\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLF2wlNkuulf"
      },
      "source": [
        "To print all annotations a sentence, token or mention has, you can simply print the corresponding obejct."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fn8xLrYaubAu",
        "outputId": "b3dbafba-9298-4e94-d2be-63086b4cd283"
      },
      "source": [
        "# Print annotations of a token\n",
        "print(document.sentence[0].token[0])\n",
        "\n",
        "# Print annotations of a mention\n",
        "print(document.sentence[0].mentions[0])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word: \"Albert\"\n",
            "pos: \"NNP\"\n",
            "value: \"Albert\"\n",
            "before: \"\"\n",
            "after: \" \"\n",
            "originalText: \"Albert\"\n",
            "ner: \"PERSON\"\n",
            "lemma: \"Albert\"\n",
            "beginChar: 0\n",
            "endChar: 6\n",
            "utterance: 0\n",
            "speaker: \"PER0\"\n",
            "beginIndex: 0\n",
            "endIndex: 1\n",
            "tokenBeginIndex: 0\n",
            "tokenEndIndex: 1\n",
            "hasXmlContext: false\n",
            "isNewline: false\n",
            "coarseNER: \"PERSON\"\n",
            "fineGrainedNER: \"PERSON\"\n",
            "corefMentionIndex: 0\n",
            "entityMentionIndex: 0\n",
            "nerLabelProbs: \"PERSON=0.9999331283889166\"\n",
            "\n",
            "sentenceIndex: 0\n",
            "tokenStartInSentenceInclusive: 0\n",
            "tokenEndInSentenceExclusive: 2\n",
            "ner: \"PERSON\"\n",
            "entityType: \"PERSON\"\n",
            "entityMentionIndex: 0\n",
            "canonicalEntityMentionIndex: 0\n",
            "entityMentionText: \"Albert Einstein\"\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zy9-S9MOihzI",
        "outputId": "0f4f928c-134d-493f-acbf-634af6548bb9"
      },
      "source": [
        "  # get the first sentence\n",
        "sentence = document.sentence[0]\n",
        "    \n",
        "# get the constituency parse of the first sentence\n",
        "print('---')\n",
        "print('constituency parse of first sentence')\n",
        "constituency_parse = sentence.parseTree\n",
        "print(constituency_parse)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---\n",
            "constituency parse of first sentence\n",
            "child {\n",
            "  child {\n",
            "    child {\n",
            "      child {\n",
            "        value: \"Albert\"\n",
            "      }\n",
            "      value: \"NNP\"\n",
            "      score: -8.849637985229492\n",
            "    }\n",
            "    child {\n",
            "      child {\n",
            "        value: \"Einstein\"\n",
            "      }\n",
            "      value: \"NNP\"\n",
            "      score: -10.39391803741455\n",
            "    }\n",
            "    value: \"NP\"\n",
            "    score: -22.208171844482422\n",
            "  }\n",
            "  child {\n",
            "    child {\n",
            "      child {\n",
            "        value: \"was\"\n",
            "      }\n",
            "      value: \"VBD\"\n",
            "      score: -0.42985981702804565\n",
            "    }\n",
            "    child {\n",
            "      child {\n",
            "        child {\n",
            "          value: \"a\"\n",
            "        }\n",
            "        value: \"DT\"\n",
            "        score: -1.5601264238357544\n",
            "      }\n",
            "      child {\n",
            "        child {\n",
            "          child {\n",
            "            value: \"German\"\n",
            "          }\n",
            "          value: \"JJ\"\n",
            "          score: -5.692482948303223\n",
            "        }\n",
            "        child {\n",
            "          child {\n",
            "            value: \"-\"\n",
            "          }\n",
            "          value: \"HYPH\"\n",
            "          score: -0.01210630964487791\n",
            "        }\n",
            "        child {\n",
            "          child {\n",
            "            value: \"born\"\n",
            "          }\n",
            "          value: \"VBN\"\n",
            "          score: -5.775586128234863\n",
            "        }\n",
            "        value: \"ADJP\"\n",
            "        score: -15.493135452270508\n",
            "      }\n",
            "      child {\n",
            "        child {\n",
            "          value: \"theoretical\"\n",
            "        }\n",
            "        value: \"JJ\"\n",
            "        score: -9.2328519821167\n",
            "      }\n",
            "      child {\n",
            "        child {\n",
            "          value: \"physicist\"\n",
            "        }\n",
            "        value: \"NN\"\n",
            "        score: -11.6840181350708\n",
            "      }\n",
            "      value: \"NP\"\n",
            "      score: -43.543113708496094\n",
            "    }\n",
            "    value: \"VP\"\n",
            "    score: -51.38176727294922\n",
            "  }\n",
            "  child {\n",
            "    child {\n",
            "      value: \".\"\n",
            "    }\n",
            "    value: \".\"\n",
            "    score: -0.05752464756369591\n",
            "  }\n",
            "  value: \"S\"\n",
            "  score: -74.78398132324219\n",
            "}\n",
            "value: \"ROOT\"\n",
            "score: -74.95536041259766\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Vcwv9sIlwZb",
        "outputId": "f73d18fc-1480-41d5-d0c6-6e2ef4cbac6c"
      },
      "source": [
        " # get the first subtree of the constituency parse\n",
        "print('first subtree of constituency parse')\n",
        "print(constituency_parse.child[0])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first subtree of constituency parse\n",
            "child {\n",
            "  child {\n",
            "    child {\n",
            "      value: \"Albert\"\n",
            "    }\n",
            "    value: \"NNP\"\n",
            "    score: -8.849637985229492\n",
            "  }\n",
            "  child {\n",
            "    child {\n",
            "      value: \"Einstein\"\n",
            "    }\n",
            "    value: \"NNP\"\n",
            "    score: -10.39391803741455\n",
            "  }\n",
            "  value: \"NP\"\n",
            "  score: -22.208171844482422\n",
            "}\n",
            "child {\n",
            "  child {\n",
            "    child {\n",
            "      value: \"was\"\n",
            "    }\n",
            "    value: \"VBD\"\n",
            "    score: -0.42985981702804565\n",
            "  }\n",
            "  child {\n",
            "    child {\n",
            "      child {\n",
            "        value: \"a\"\n",
            "      }\n",
            "      value: \"DT\"\n",
            "      score: -1.5601264238357544\n",
            "    }\n",
            "    child {\n",
            "      child {\n",
            "        child {\n",
            "          value: \"German\"\n",
            "        }\n",
            "        value: \"JJ\"\n",
            "        score: -5.692482948303223\n",
            "      }\n",
            "      child {\n",
            "        child {\n",
            "          value: \"-\"\n",
            "        }\n",
            "        value: \"HYPH\"\n",
            "        score: -0.01210630964487791\n",
            "      }\n",
            "      child {\n",
            "        child {\n",
            "          value: \"born\"\n",
            "        }\n",
            "        value: \"VBN\"\n",
            "        score: -5.775586128234863\n",
            "      }\n",
            "      value: \"ADJP\"\n",
            "      score: -15.493135452270508\n",
            "    }\n",
            "    child {\n",
            "      child {\n",
            "        value: \"theoretical\"\n",
            "      }\n",
            "      value: \"JJ\"\n",
            "      score: -9.2328519821167\n",
            "    }\n",
            "    child {\n",
            "      child {\n",
            "        value: \"physicist\"\n",
            "      }\n",
            "      value: \"NN\"\n",
            "      score: -11.6840181350708\n",
            "    }\n",
            "    value: \"NP\"\n",
            "    score: -43.543113708496094\n",
            "  }\n",
            "  value: \"VP\"\n",
            "  score: -51.38176727294922\n",
            "}\n",
            "child {\n",
            "  child {\n",
            "    value: \".\"\n",
            "  }\n",
            "  value: \".\"\n",
            "  score: -0.05752464756369591\n",
            "}\n",
            "value: \"S\"\n",
            "score: -74.78398132324219\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FM_DsQWZmnZL",
        "outputId": "11c1b378-2745-4852-9c8a-c14881e394fb"
      },
      "source": [
        "# get the value of the first subtree\n",
        "print('---')\n",
        "print('value of first subtree of constituency parse')\n",
        "print(constituency_parse.child[0].value)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---\n",
            "value of first subtree of constituency parse\n",
            "S\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSTZso4OnONp",
        "outputId": "4a2df616-e457-4ea6-ed0b-3b721cc83697"
      },
      "source": [
        "  # get the first token of the first sentence\n",
        "print('first token of first sentence')\n",
        "token = sentence.token[0]\n",
        "print(token)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first token of first sentence\n",
            "word: \"Albert\"\n",
            "pos: \"NNP\"\n",
            "value: \"Albert\"\n",
            "before: \"\"\n",
            "after: \" \"\n",
            "originalText: \"Albert\"\n",
            "ner: \"PERSON\"\n",
            "lemma: \"Albert\"\n",
            "beginChar: 0\n",
            "endChar: 6\n",
            "utterance: 0\n",
            "speaker: \"PER0\"\n",
            "beginIndex: 0\n",
            "endIndex: 1\n",
            "tokenBeginIndex: 0\n",
            "tokenEndIndex: 1\n",
            "hasXmlContext: false\n",
            "isNewline: false\n",
            "coarseNER: \"PERSON\"\n",
            "fineGrainedNER: \"PERSON\"\n",
            "corefMentionIndex: 0\n",
            "entityMentionIndex: 0\n",
            "nerLabelProbs: \"PERSON=0.9999331283889166\"\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lv4zz0FuoGQz",
        "outputId": "5e968767-c9fe-4b82-9322-d852ebd4409f"
      },
      "source": [
        "  # get the part-of-speech tag\n",
        "print('part of speech tag of token')\n",
        "token.pos\n",
        "print(token.pos)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "part of speech tag of token\n",
            "NNP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zW-vv45loTRO",
        "outputId": "c08f2c19-217e-4adf-aa94-8e0e3880d1dd"
      },
      "source": [
        "# get the named entity tag\n",
        "print('named entity tag of token')\n",
        "print(token.ner)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "named entity tag of token\n",
            "PERSON\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aItouLkmodwk",
        "outputId": "070ef163-f894-4e26-f925-f449bda94eaf"
      },
      "source": [
        "# get an entity mention from the first sentence\n",
        "print('first entity mention in sentence')\n",
        "print(sentence.mentions[0])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first entity mention in sentence\n",
            "sentenceIndex: 0\n",
            "tokenStartInSentenceInclusive: 0\n",
            "tokenEndInSentenceExclusive: 2\n",
            "ner: \"PERSON\"\n",
            "entityType: \"PERSON\"\n",
            "entityMentionIndex: 0\n",
            "canonicalEntityMentionIndex: 0\n",
            "entityMentionText: \"Albert Einstein\"\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjMw32LuouwD",
        "outputId": "f22afcf0-c8e3-44ef-e860-a1336db666fa"
      },
      "source": [
        " # access the coref chain\n",
        "print('coref chains for the example')\n",
        "print(document.corefChain)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "coref chains for the example\n",
            "[chainID: 2\n",
            "mention {\n",
            "  mentionID: 0\n",
            "  mentionType: \"PROPER\"\n",
            "  number: \"SINGULAR\"\n",
            "  gender: \"MALE\"\n",
            "  animacy: \"ANIMATE\"\n",
            "  beginIndex: 0\n",
            "  endIndex: 2\n",
            "  headIndex: 1\n",
            "  sentenceIndex: 0\n",
            "  position: 1\n",
            "}\n",
            "mention {\n",
            "  mentionID: 2\n",
            "  mentionType: \"PRONOMINAL\"\n",
            "  number: \"SINGULAR\"\n",
            "  gender: \"MALE\"\n",
            "  animacy: \"ANIMATE\"\n",
            "  beginIndex: 0\n",
            "  endIndex: 1\n",
            "  headIndex: 0\n",
            "  sentenceIndex: 1\n",
            "  position: 1\n",
            "}\n",
            "representative: 0\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "at9GdgxQrdub",
        "outputId": "3570d69f-b786-4b5f-a51a-efefb9240c50"
      },
      "source": [
        "mychains = list()\n",
        "chains = document.corefChain\n",
        "for chain in chains:\n",
        "    mychain = list()\n",
        "    # Loop through every mention of this chain\n",
        "    for mention in chain.mention:\n",
        "        # Get the sentence in which this mention is located, and get the words which are part of this mention\n",
        "        # (we can have more than one word, for example, a mention can be a pronoun like \"he\", but also a compound noun like \"His wife Michelle\")\n",
        "        words_list = document.sentence[mention.sentenceIndex].token[mention.beginIndex:mention.endIndex]\n",
        "        #build a string out of the words of this mention\n",
        "        ment_word = ' '.join([x.word for x in words_list])\n",
        "        mychain.append(ment_word)\n",
        "    mychains.append(mychain)\n",
        "\n",
        "for chain in mychains:\n",
        "    print(' <-> '.join(chain))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Albert Einstein <-> He\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45psltbBu9qq"
      },
      "source": [
        "Shutting Down the CoreNLP Server\n",
        "\n",
        "To shut down the background CoreNLP server process, simply call the stop function of the client. Note that once a server is shutdown, you'll have to restart the server with the start() function before any annotation is requested."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e8SN2AAgYY6",
        "outputId": "af879d31-6288-45c3-d50c-018ee351674e"
      },
      "source": [
        "# Shut down the background CoreNLP server\n",
        "client.stop()\n",
        "\n",
        "time.sleep(10)\n",
        "!ps -o pid,cmd | grep java"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    262 /bin/bash -c ps -o pid,cmd | grep java\n",
            "    264 grep java\n"
          ]
        }
      ]
    }
  ]
}