{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ICP_5.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPEIsE4AU2/Y6im9eR38YNW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zbutton314/CS-5560/blob/main/Lab5/code/ICP_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Environment Setup"
      ],
      "metadata": {
        "id": "cieJKyVR8Orh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxvgRX4lJEkV",
        "outputId": "496a56cd-f276-48fa-9446-10d33e70d89f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 44 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.3\n",
            "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 69.5 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=2942a526706130fc3970f81620af820a792757ca3eecbe10bafa2701ee10703b\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "from __future__ import print_function\n",
        "from pyspark import SparkConf, SparkContext\n",
        "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, CountVectorizer\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import NGram\n",
        "from pyspark.ml.feature import Word2Vec\n",
        "import pandas as pd\n",
        "import re\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "F1e7M1eCS3Lh"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.wordnet import WordNetLemmatizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Un5zsO6vbAQ",
        "outputId": "e13a629a-0911-4267-e395-80b94a9928f6"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName(\"ICP-5\").getOrCreate()"
      ],
      "metadata": {
        "id": "dO3FxZL7TjCj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "\n",
        "icp5_data_path = \"/content/drive/MyDrive/data/ICP-5\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zG_RNrloS3W0",
        "outputId": "f18be3f7-aea5-4845-ec65-c91e84611ff6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Data"
      ],
      "metadata": {
        "id": "J9IRm8yh8Sx-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simple function to import and clean text file"
      ],
      "metadata": {
        "id": "vTFzQZ9u8VD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def import_text(path):\n",
        "  with open(path, 'r') as file:\n",
        "    s = file.read().rstrip().replace(u'\\xa0', u' ')\n",
        "\n",
        "  s = re.sub(r\"\\[[0-9]*\\]\", \"\", s)\n",
        "\n",
        "  return s\n"
      ],
      "metadata": {
        "id": "9SidY9mDZhRI"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import each of the 5 example text files"
      ],
      "metadata": {
        "id": "LKFIRGIB8c1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apache Spark\n",
        "path_apache = f\"{icp5_data_path}/Apache_Spark.txt\"\n",
        "str_apache = import_text(path_apache)\n",
        "print(f\"{path_apache.split('/')[-1]} imported: {len(str_apache)} characters\")\n",
        "\n",
        "# Spark (Fire)\n",
        "path_fire = f\"{icp5_data_path}/Spark.txt\"\n",
        "str_fire = import_text(path_fire)\n",
        "print(f\"{path_fire.split('/')[-1]} imported: {len(str_fire)} characters\")\n",
        "\n",
        "# Chevrolet Spark\n",
        "path_chevy = f\"{icp5_data_path}/Chevrolet_Spark.txt\"\n",
        "str_chevy = import_text(path_chevy)\n",
        "print(f\"{path_chevy.split('/')[-1]} imported: {len(str_chevy)} characters\")\n",
        "\n",
        "# Ayla Ranzz (aka Spark)\n",
        "path_ayla = f\"{icp5_data_path}/Ayla_Ranzz.txt\"\n",
        "str_ayla = import_text(path_ayla)\n",
        "print(f\"{path_ayla.split('/')[-1]} imported: {len(str_ayla)} characters\")\n",
        "\n",
        "# Jordin Sparks\n",
        "path_jordin = f\"{icp5_data_path}/Jordin_Sparks.txt\"\n",
        "str_jordin = import_text(path_jordin)\n",
        "print(f\"{path_jordin.split('/')[-1]} imported: {len(str_jordin)} characters\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubCm6YEeS3hC",
        "outputId": "a637136a-eafd-476f-8fdc-98bebf42fbc6"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apache_Spark.txt imported: 9267 characters\n",
            "Spark.txt imported: 6659 characters\n",
            "Chevrolet_Spark.txt imported: 26672 characters\n",
            "Ayla_Ranzz.txt imported: 10754 characters\n",
            "Jordin_Sparks.txt imported: 35819 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TF-IDF"
      ],
      "metadata": {
        "id": "MIISH2Z6hXXH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function for finding top TF-IDF words"
      ],
      "metadata": {
        "id": "rVEwfrIksZz9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_top_tf_idf(spark_df, n, input_col):\n",
        "  # Find term frequencies\n",
        "  vectorizer = CountVectorizer(inputCol=input_col, outputCol=\"rawFeatures\").fit(spark_df)\n",
        "  featurizedData = vectorizer.transform(spark_df)\n",
        "\n",
        "  # Rescale data (IDF)\n",
        "  idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
        "  idfModel = idf.fit(featurizedData)\n",
        "  rescaledData = idfModel.transform(featurizedData)\n",
        "\n",
        "  # Create data frame for results\n",
        "  vocab = vectorizer.vocabulary\n",
        "  df = pd.DataFrame({\"index\": range(len(vocab)), \"word\": vectorizer.vocabulary})\n",
        "\n",
        "  # Place each document's TF-IDF values into data frame\n",
        "  for i, name in enumerate([\"apache\", \"fire\", \"chevy\", \"ayla\", \"jordin\"]):\n",
        "    df[f\"features_{name}\"] = rescaledData.select(\"features\").collect()[i][0].toArray()\n",
        "\n",
        "  # Print top n TF-IDF words for each document\n",
        "  d = {}\n",
        "  for col in df.columns[2:]:\n",
        "    doc = col.split(\"_\")[-1]\n",
        "    top_words = df.sort_values(col, ascending=False).head(n)[\"word\"].values\n",
        "    d[doc] = top_words\n",
        "\n",
        "  return d"
      ],
      "metadata": {
        "id": "de4SslNLrI6H"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Find top words from raw input"
      ],
      "metadata": {
        "id": "Q1mMMm6csdN0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rawData = spark.createDataFrame([\n",
        "        (0.0, str_apache),\n",
        "        (0.1, str_fire),\n",
        "        (0.2, str_chevy),\n",
        "        (0.3, str_ayla),\n",
        "        (0.4, str_jordin)\n",
        "    ], [\"label\", \"text\"])\n",
        "\n",
        "# Tokenize raw text data\n",
        "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
        "wordsData = tokenizer.transform(rawData)\n",
        "\n",
        "results_raw = find_top_tf_idf(spark_df=wordsData, n=10, input_col=\"words\")\n",
        "\n",
        "for doc in results_raw.keys():\n",
        "  print(f\"{doc}: {results_raw[doc]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XPAIrLHsL0F",
        "outputId": "f63ebff7-549f-4e3c-eee2-cca79903958c"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "apache: ['apache' 'data' 'rdd' 'spark' 'streaming' 'rdds' 'interface' 'cluster'\n",
            " 'graphx' 'algorithms']\n",
            "fire: ['sparks' 'metal' 'sparks.' 'steel' 'especially' 'fire' 'vapor' 'low'\n",
            " 'burns' 'temperature']\n",
            "chevy: ['chevrolet' 'matiz' 'car' 'gm' 'daewoo' 'beat' 'marketed' 'south' 'sold'\n",
            " 'model']\n",
            "ayla: ['her' 'she' 'ayla' 'legion' 'lightning' 'powers' 'lass' 'brother' 'garth'\n",
            " 'ranzz']\n",
            "jordin: ['sparks' 'her' 'music' 'she' \"sparks's\" 'song' 'album' 'number'\n",
            " 'american' 'performed']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Find top words from lemmatized input"
      ],
      "metadata": {
        "id": "PXKsgz6GuGx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words_apache = word_tokenize(str_apache)\n",
        "words_fire = word_tokenize(str_fire)\n",
        "words_chevy = word_tokenize(str_chevy)\n",
        "words_ayla = word_tokenize(str_ayla)\n",
        "words_jordin = word_tokenize(str_jordin)\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmas_apache = [lemmatizer.lemmatize(w) for w in words_apache]\n",
        "lemmas_fire = [lemmatizer.lemmatize(w) for w in words_fire]\n",
        "lemmas_chevy = [lemmatizer.lemmatize(w) for w in words_chevy]\n",
        "lemmas_ayla = [lemmatizer.lemmatize(w) for w in words_ayla]\n",
        "lemmas_jordin = [lemmatizer.lemmatize(w) for w in words_jordin]\n",
        "\n",
        "lemmasData = spark.createDataFrame([\n",
        "        (0.0, lemmas_apache),\n",
        "        (0.1, lemmas_fire),\n",
        "        (0.2, lemmas_chevy),\n",
        "        (0.3, lemmas_ayla),\n",
        "        (0.4, lemmas_jordin)\n",
        "    ], [\"label\", \"lemmas\"])\n",
        "\n",
        "results_lemma = find_top_tf_idf(spark_df=lemmasData, n=10, input_col=\"lemmas\")\n",
        "\n",
        "for doc in results_lemma.keys():\n",
        "  print(f\"{doc}: {results_lemma[doc]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HS1WWx2BtN6c",
        "outputId": "80b7d479-ce31-4a5c-95a4-bfbfddc5ed55"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "apache: ['data' 'Apache' 'RDD' 'RDDs' 'API' 'interface' 'Spark' 'support'\n",
            " 'algorithm' 'GraphX']\n",
            "fire: ['spark' 'metal' 'fire' 'particle' 'steel' 'welding' 'phase' 'flint'\n",
            " 'burn' 'especially']\n",
            "chevy: ['Chevrolet' 'car' 'Matiz' 'GM' 'Daewoo' 'India' 'sold' 'marketed' 'South'\n",
            " 'trim']\n",
            "ayla: ['her' 'Legion' 'Ayla' 'she' 'Lightning' 'power' 'Lass' 'brother' 'Garth'\n",
            " 'She']\n",
            "jordin: ['Sparks' 'her' 'album' 'song' 'On' 'Idol' 'Music' 'single' 'I' 'number']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Find top words from n-gram input"
      ],
      "metadata": {
        "id": "6sec9U44xr-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rawData = spark.createDataFrame([\n",
        "        (0.0, str_apache),\n",
        "        (0.1, str_fire),\n",
        "        (0.2, str_chevy),\n",
        "        (0.3, str_ayla),\n",
        "        (0.4, str_jordin)\n",
        "    ], [\"label\", \"text\"])\n",
        "\n",
        "# Tokenize raw text data\n",
        "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
        "wordsData = tokenizer.transform(rawData)\n",
        "\n",
        "ngram = NGram(n=2, inputCol=\"words\", outputCol=\"ngrams\")\n",
        "ngramsData = ngram.transform(wordsData)\n",
        "\n",
        "results_ngram = find_top_tf_idf(spark_df=ngramsData, n=10, input_col=\"ngrams\")\n",
        "\n",
        "for doc in results_ngram.keys():\n",
        "  print(f\"{doc}: {results_ngram[doc]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaW9yD9NsW6p",
        "outputId": "dafa39f2-9008-45fc-8d8e-e0d22fbec9bc"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "apache: ['apache spark' 'top of' 'the rdd' 'on top' 'the apache' 'apache software'\n",
            " 'machine learning' 'spark core' 'api is' 'spark sql']\n",
            "fire: ['sparks. the' 'and so' 'color of' 'the sparks' 'of sparks' 'sparks can'\n",
            " 'the color' ' ' 'sparks when' 'molten metal']\n",
            "chevy: ['the chevrolet' 'chevrolet spark' 'the matiz' 'the car' 'version was'\n",
            " 'the daewoo' 'spark ev' 'in south' 'matiz was' 'the beat']\n",
            "ayla: ['the legion' 'legion of' 'her brother' 'light lass' 'she is'\n",
            " 'as lightning' 'ayla ranzz' 'ability to' 'she was' 'of super-heroes']\n",
            "jordin: ['announced that' 'on may' 'the song' 'sparks was' 'that sparks'\n",
            " 'on november' 'american idol' 'at number' 'the billboard' 'sparks would']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# W2V"
      ],
      "metadata": {
        "id": "p4cHJkcV1YXD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Find W2V similar words using cosine similarity"
      ],
      "metadata": {
        "id": "36Gbps9Y1Zur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_similarities(mode, vector_size, doc_selection=\"all\"):\n",
        "  if mode == \"raw\":\n",
        "    spark_df = wordsData\n",
        "    input_col = \"words\"\n",
        "    results_dict = results_raw\n",
        "  elif mode == \"lemmas\":\n",
        "    spark_df = lemmasData\n",
        "    input_col = \"lemmas\"\n",
        "    results_dict = results_lemma\n",
        "  elif mode == \"ngrams\":\n",
        "    spark_df = ngramsData\n",
        "    input_col = \"ngrams\"\n",
        "    results_dict = results_ngram\n",
        "  else:\n",
        "    print(\"Invalid mode: choose raw, lemmas, or ngrams\")\n",
        "    sys.exit()\n",
        "\n",
        "  if doc_selection == \"all\":\n",
        "    selected_docs = results_dict.keys()\n",
        "  else:\n",
        "    selected_docs = [doc_selection]\n",
        "\n",
        "  word2Vec = Word2Vec(vectorSize=vector_size, minCount=0, inputCol=input_col, \n",
        "                      outputCol=\"result\")\n",
        "  model = word2Vec.fit(spark_df)\n",
        "\n",
        "  for doc in selected_docs:\n",
        "    print(f\"COMPUTING FOR {doc}...\\n\")\n",
        "    top_words = results_dict[doc]\n",
        "    for word in top_words:\n",
        "      print(f\"-- Top Cosine Similarities for {word}:\")\n",
        "      synonyms = model.findSynonyms(word, 5)\n",
        "      synonyms.show(5)"
      ],
      "metadata": {
        "id": "lJNK9PGlsWxp"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Top \"synonyms\" for apache document, using raw data\n",
        "\n"
      ],
      "metadata": {
        "id": "0KTN3Ezh71pA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "find_similarities(mode=\"raw\", vector_size=10, doc_selection=\"apache\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rG0XCfU-S3_y",
        "outputId": "9a003efd-fe91-42ca-ad5f-88dcb3879d9c"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COMPUTING FOR apache...\n",
            "\n",
            "-- Top Cosine Similarities for apache:\n",
            "+--------+------------------+\n",
            "|    word|        similarity|\n",
            "+--------+------------------+\n",
            "| arrived|0.9133138656616211|\n",
            "|    days|0.8859877586364746|\n",
            "|admitted|  0.84316486120224|\n",
            "|     kin|0.8406805396080017|\n",
            "|unveiled|0.8324633240699768|\n",
            "+--------+------------------+\n",
            "\n",
            "-- Top Cosine Similarities for data:\n",
            "+-------+------------------+\n",
            "|   word|        similarity|\n",
            "+-------+------------------+\n",
            "|  spill|0.8955745697021484|\n",
            "|   kid.| 0.878497302532196|\n",
            "|(2012).|0.8733638525009155|\n",
            "|  songs|0.8370116353034973|\n",
            "|single.|0.8304732441902161|\n",
            "+-------+------------------+\n",
            "\n",
            "-- Top Cosine Similarities for rdd:\n",
            "+-----------+------------------+\n",
            "|       word|        similarity|\n",
            "+-----------+------------------+\n",
            "|     love\",|0.8870320916175842|\n",
            "|   america.| 0.824679970741272|\n",
            "|parallelism| 0.810459554195404|\n",
            "|  datasets,|0.7990445494651794|\n",
            "|   alluxio,|0.7912497520446777|\n",
            "+-----------+------------------+\n",
            "\n",
            "-- Top Cosine Similarities for spark:\n",
            "+----------+------------------+\n",
            "|      word|        similarity|\n",
            "+----------+------------------+\n",
            "|       car| 0.980783224105835|\n",
            "|  launched|0.9785330295562744|\n",
            "|      sold|0.9772676229476929|\n",
            "|production|0.9746727347373962|\n",
            "|   version|0.9737436771392822|\n",
            "+----------+------------------+\n",
            "\n",
            "-- Top Cosine Similarities for streaming:\n",
            "+---------------+------------------+\n",
            "|           word|        similarity|\n",
            "+---------------+------------------+\n",
            "|       mcbride.|0.8742397427558899|\n",
            "|        \"jordin|0.8713241815567017|\n",
            "|         \"count|0.8657464385032654|\n",
            "|          fault|0.8634399175643921|\n",
            "|uzbekistan-made| 0.858705461025238|\n",
            "+---------------+------------------+\n",
            "\n",
            "-- Top Cosine Similarities for rdds:\n",
            "+---------+------------------+\n",
            "|     word|        similarity|\n",
            "+---------+------------------+\n",
            "|   rejoin|0.8547277450561523|\n",
            "|   poland|0.8540552854537964|\n",
            "|     grey|0.8299765586853027|\n",
            "|2018-2021|0.8100928664207458|\n",
            "|     trap|0.7960745096206665|\n",
            "+---------+------------------+\n",
            "\n",
            "-- Top Cosine Similarities for interface:\n",
            "+--------+------------------+\n",
            "|    word|        similarity|\n",
            "+--------+------------------+\n",
            "|    bolt|0.9221107363700867|\n",
            "|    year|0.8997317552566528|\n",
            "|  louder|0.8742663264274597|\n",
            "|argument|0.8414788246154785|\n",
            "|   older|0.8252384066581726|\n",
            "+--------+------------------+\n",
            "\n",
            "-- Top Cosine Similarities for cluster:\n",
            "+-------------+------------------+\n",
            "|         word|        similarity|\n",
            "+-------------+------------------+\n",
            "|        stand|0.9033997058868408|\n",
            "|preproduction|0.8724024295806885|\n",
            "|        naive| 0.861916184425354|\n",
            "|  regression,| 0.857985258102417|\n",
            "|   operations|0.8558233380317688|\n",
            "+-------------+------------------+\n",
            "\n",
            "-- Top Cosine Similarities for graphx:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyspark/sql/context.py:127: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------------------+\n",
            "|       word|        similarity|\n",
            "+-----------+------------------+\n",
            "|manufacture|0.8856542110443115|\n",
            "|   multiple|0.8686760067939758|\n",
            "|       21.3|0.8685535192489624|\n",
            "|    parking|0.8621446490287781|\n",
            "|   website,|0.8157819509506226|\n",
            "+-----------+------------------+\n",
            "\n",
            "-- Top Cosine Similarities for algorithms:\n",
            "+------------+------------------+\n",
            "|        word|        similarity|\n",
            "+------------+------------------+\n",
            "|introduction|0.9230805039405823|\n",
            "|       lad's|0.8834492564201355|\n",
            "|      engine|0.8758612275123596|\n",
            "|    version,| 0.870771050453186|\n",
            "|       power|0.8691269159317017|\n",
            "+------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Top \"synonyms\" for apache document, using lemmatized data"
      ],
      "metadata": {
        "id": "qT8ibo1v7HGt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "find_similarities(mode=\"lemmas\", vector_size=10, doc_selection=\"apache\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqQGwyGUS4G2",
        "outputId": "bd7421f1-e853-464b-ecde-8cd57e57c5b5"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COMPUTING FOR apache...\n",
            "\n",
            "-- Top Cosine Similarities for Apache:\n",
            "+---------+------------------+\n",
            "|     word|        similarity|\n",
            "+---------+------------------+\n",
            "|      hot|0.9629665017127991|\n",
            "|     used|0.9607371091842651|\n",
            "|automatic|0.9549303650856018|\n",
            "|     till|0.9545678496360779|\n",
            "|     than|0.9429707527160645|\n",
            "+---------+------------------+\n",
            "\n",
            "-- Top Cosine Similarities for data:\n",
            "+-----+------------------+\n",
            "| word|        similarity|\n",
            "+-----+------------------+\n",
            "|still|0.9749342799186707|\n",
            "| used|0.9702635407447815|\n",
            "|   us|0.9697751402854919|\n",
            "|brand|  0.96111661195755|\n",
            "| fire|0.9563091993331909|\n",
            "+-----+------------------+\n",
            "\n",
            "-- Top Cosine Similarities for RDD:\n",
            "+--------+------------------+\n",
            "|    word|        similarity|\n",
            "+--------+------------------+\n",
            "|Eldritch|0.9255056977272034|\n",
            "|titanium|0.8345174193382263|\n",
            "|performs|0.8333288431167603|\n",
            "| January|0.8236171007156372|\n",
            "|  record|0.7977603673934937|\n",
            "+--------+------------------+\n",
            "\n",
            "-- Top Cosine Similarities for RDDs:\n",
            "+------------+------------------+\n",
            "|        word|        similarity|\n",
            "+------------+------------------+\n",
            "|  Foundation|0.9227846264839172|\n",
            "|introduction|  0.88509601354599|\n",
            "|       final|0.8803209066390991|\n",
            "|      'Spark|0.8680050373077393|\n",
            "|       deity|0.8529624342918396|\n",
            "+------------+------------------+\n",
            "\n",
            "-- Top Cosine Similarities for interface:\n",
            "+-----------+------------------+\n",
            "|       word|        similarity|\n",
            "+-----------+------------------+\n",
            "|manual/auto|0.9278358817100525|\n",
            "|    thermal|0.8994696140289307|\n",
            "|    economy|0.8839905858039856|\n",
            "|    license|0.8818124532699585|\n",
            "|   devoured|0.8750995397567749|\n",
            "+-----------+------------------+\n",
            "\n",
            "-- Top Cosine Similarities for API:\n",
            "+-----------+------------------+\n",
            "|       word|        similarity|\n",
            "+-----------+------------------+\n",
            "|RDD-centric|0.9066706895828247|\n",
            "|  displayed|0.8846818208694458|\n",
            "|      drive|0.8553792238235474|\n",
            "|       born| 0.845513105392456|\n",
            "|    license|0.8426781296730042|\n",
            "+-----------+------------------+\n",
            "\n",
            "-- Top Cosine Similarities for Spark:\n",
            "+-------+------------------+\n",
            "|   word|        similarity|\n",
            "+-------+------------------+\n",
            "|  Activ|0.9764631390571594|\n",
            "|  start|0.9745712876319885|\n",
            "|version|0.9740893840789795|\n",
            "|  Matiz|0.9734237194061279|\n",
            "| dealer|0.9692362546920776|\n",
            "+-------+------------------+\n",
            "\n",
            "-- Top Cosine Similarities for support:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyspark/sql/context.py:127: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------------------+\n",
            "|       word|        similarity|\n",
            "+-----------+------------------+\n",
            "|      being|0.9533401131629944|\n",
            "|    trouble|0.9428126215934753|\n",
            "|      front|0.9362180829048157|\n",
            "|environment|0.9333353638648987|\n",
            "|       from|0.9205324053764343|\n",
            "+-----------+------------------+\n",
            "\n",
            "-- Top Cosine Similarities for program:\n",
            "+----------+------------------+\n",
            "|      word|        similarity|\n",
            "+----------+------------------+\n",
            "|      Wolf|0.8926135897636414|\n",
            "|      teen|0.8474096059799194|\n",
            "|   holiday|0.8346070647239685|\n",
            "|non-profit|0.8344035148620605|\n",
            "|explaining|0.8287461400032043|\n",
            "+----------+------------------+\n",
            "\n",
            "-- Top Cosine Similarities for function:\n",
            "+-----------+------------------+\n",
            "|       word|        similarity|\n",
            "+-----------+------------------+\n",
            "|    17-inch|0.8593699336051941|\n",
            "|alternating|0.8189995884895325|\n",
            "| scheduling| 0.809699296951294|\n",
            "|       Gulf|0.8060097694396973|\n",
            "|       deal|0.8007938861846924|\n",
            "+-----------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Top \"synonyms\" for apache document, using n-gram data"
      ],
      "metadata": {
        "id": "Djbr_kmc7Gip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "find_similarities(mode=\"ngrams\", vector_size=10, doc_selection=\"apache\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkoQZ9xG7F4L",
        "outputId": "55306357-6c7c-4262-ca5b-8a91394f9fbe"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COMPUTING FOR apache...\n",
            "\n",
            "-- Top Cosine Similarities for apache spark:\n",
            "+-----------------+------------------+\n",
            "|             word|        similarity|\n",
            "+-----------------+------------------+\n",
            "|sun-eater. later,| 0.939329206943512|\n",
            "|       her native|0.9139214158058167|\n",
            "|     episode. the|0.9130833148956299|\n",
            "|    broadway. she|0.9070369601249695|\n",
            "|received numerous| 0.904209554195404|\n",
            "+-----------------+------------------+\n",
            "\n",
            "-- Top Cosine Similarities for on top:\n",
            "+--------------------+------------------+\n",
            "|                word|        similarity|\n",
            "+--------------------+------------------+\n",
            "|            began at|0.9341737627983093|\n",
            "|     the opportunity| 0.922924816608429|\n",
            "|outlet.[citation ...|0.8885645866394043|\n",
            "|           film left|0.8702558279037476|\n",
            "|              a city|0.8697482943534851|\n",
            "+--------------------+------------------+\n",
            "\n",
            "-- Top Cosine Similarities for the rdd:\n",
            "+--------------------+------------------+\n",
            "|                word|        similarity|\n",
            "+--------------------+------------------+\n",
            "|         vehicles in|0.9091590642929077|\n",
            "|        a community.|0.8791897892951965|\n",
            "|    maryland. sparks|0.8698151707649231|\n",
            "|automatic transmi...|0.8569734692573547|\n",
            "|         tickford, a|0.8391183614730835|\n",
            "+--------------------+------------------+\n",
            "\n",
            "-- Top Cosine Similarities for the apache:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyspark/sql/context.py:127: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+------------------+\n",
            "|               word|        similarity|\n",
            "+-------------------+------------------+\n",
            "|super-heroes. there|0.9346035718917847|\n",
            "|      holden barina|0.8798717260360718|\n",
            "|      as pagerank):| 0.862449049949646|\n",
            "|           new song|0.8458932638168335|\n",
            "|         \"five year|0.8370183110237122|\n",
            "+-------------------+------------------+\n",
            "\n",
            "-- Top Cosine Similarities for apache software:\n",
            "+-----------+------------------+\n",
            "|       word|        similarity|\n",
            "+-----------+------------------+\n",
            "|  spears on|0.9276765584945679|\n",
            "|m3x concept|0.9235324859619141|\n",
            "|     an 800|0.9149952530860901|\n",
            "| lighter or|0.8879521489143372|\n",
            "|  powers as|0.8864573836326599|\n",
            "+-----------+------------------+\n",
            "\n",
            "-- Top Cosine Similarities for top of:\n",
            "+---------------+------------------+\n",
            "|           word|        similarity|\n",
            "+---------------+------------------+\n",
            "|      gm halted|0.9515533447265625|\n",
            "| episode, \"keep| 0.945679783821106|\n",
            "|   bring myself|0.9402528405189514|\n",
            "|   storyline it|0.9325162768363953|\n",
            "|cord hemorrhage|  0.92739337682724|\n",
            "+---------------+------------------+\n",
            "\n",
            "-- Top Cosine Similarities for api is:\n",
            "+------------------+------------------+\n",
            "|              word|        similarity|\n",
            "+------------------+------------------+\n",
            "|          show. it|0.9045055508613586|\n",
            "|fundamental forces|0.9003949761390686|\n",
            "|        other rare|0.8980217576026917|\n",
            "|            lpg, a| 0.886907696723938|\n",
            "|        one rather|0.8822057843208313|\n",
            "+------------------+------------------+\n",
            "\n",
            "-- Top Cosine Similarities for in spark:\n",
            "+-----------------+------------------+\n",
            "|             word|        similarity|\n",
            "+-----------------+------------------+\n",
            "|battlefield tour.|0.8878279328346252|\n",
            "|         2012, gm|0.8656868934631348|\n",
            "|     developed at|0.8557381629943848|\n",
            "|        13, 2013.|0.8505826592445374|\n",
            "|       price, the|0.8473659157752991|\n",
            "+-----------------+------------------+\n",
            "\n",
            "-- Top Cosine Similarities for the dataset:\n",
            "+--------------+------------------+\n",
            "|          word|        similarity|\n",
            "+--------------+------------------+\n",
            "|     awards in|  0.94142085313797|\n",
            "|   spark, with|0.9075263142585754|\n",
            "|   universe, a| 0.903065025806427|\n",
            "|argentina, the|0.8931384682655334|\n",
            "|  bass brought|0.8908541798591614|\n",
            "+--------------+------------------+\n",
            "\n",
            "-- Top Cosine Similarities for file system:\n",
            "+--------------------+------------------+\n",
            "|                word|        similarity|\n",
            "+--------------------+------------------+\n",
            "|             gm also|0.8844537138938904|\n",
            "|electrocutes humans.|0.8607913255691528|\n",
            "|       issues within|0.8591628670692444|\n",
            "|            the 2022|0.8542934060096741|\n",
            "|           filming a|0.8524593114852905|\n",
            "+--------------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4CgYfTlz7Mos"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}