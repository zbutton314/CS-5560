{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ICP_6.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zbutton314/CS-5560/blob/main/code/ICP_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "soVuZUe9ehxc"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ljwil_IpJY24",
        "outputId": "1da7239f-837a-4fdc-d12d-c140dad8dc29"
      },
      "source": [
        "!pip install pyLDAvis"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyLDAvis\n",
            "  Downloading pyLDAvis-3.3.1.tar.gz (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 6.0 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.1.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.11.3)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.0.2)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.3.5)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.8.1)\n",
            "Collecting funcy\n",
            "  Downloading funcy-1.17-py2.py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.16.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (57.4.0)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.21.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.0->pyLDAvis) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim->pyLDAvis) (5.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->pyLDAvis) (2.0.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from numexpr->pyLDAvis) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->numexpr->pyLDAvis) (3.0.7)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyLDAvis) (3.1.0)\n",
            "Building wheels for collected packages: pyLDAvis\n",
            "  Building wheel for pyLDAvis (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyLDAvis: filename=pyLDAvis-3.3.1-py2.py3-none-any.whl size=136898 sha256=9e844f0300601f695cee0b912dd4d2bc4da6c4e6e8bb169f5926d67c67714487\n",
            "  Stored in directory: /root/.cache/pip/wheels/c9/21/f6/17bcf2667e8a68532ba2fbf6d5c72fdf4c7f7d9abfa4852d2f\n",
            "Successfully built pyLDAvis\n",
            "Installing collected packages: funcy, pyLDAvis\n",
            "Successfully installed funcy-1.17 pyLDAvis-3.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXbt5bPRGTNQ",
        "outputId": "8954240b-bfab-44c7-cdcb-839a66fa3240"
      },
      "source": [
        "import re\n",
        "import string\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from gensim import corpora, models, similarities\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import gensim\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim_models\n",
        "#import pyLDAvis.gensim\n",
        "from gensim.models import CoherenceModel\n",
        "from google.colab import drive\n",
        "import warnings\n",
        "from IPython.display import display\n",
        "import numpy as np\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "Wdqh5mU2_7uR"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WuExI9hGriq"
      },
      "source": [
        "def import_data(path):\n",
        "  reviews_df = pd.read_csv(path, error_bad_lines=False)\n",
        "  return reviews_df"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFZ7kYcaH_OL"
      },
      "source": [
        "def initial_clean(text):\n",
        "    \"\"\"\n",
        "    Function to clean text-remove punctuations, lowercase text etc.\n",
        "    \"\"\"\n",
        "    text = re.sub(\"[^a-zA-Z ]\", \"\", text)\n",
        "    text = text.lower()  # lower case text\n",
        "    text = nltk.word_tokenize(text)\n",
        "    return (text)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VWCXvWxIgfq"
      },
      "source": [
        "def remove_stop_words(text):\n",
        "  stop_words = stopwords.words('english')\n",
        "  # adding some more stop words that doesn't convey much meaning in terms of reviews feel free to extend or reduce this list\n",
        "  stop_words.extend(['news', 'say','use', 'not', 'would', 'say', 'could', '_', 'be', 'know', \n",
        "                   'good', 'go', 'get', 'do','took','time','year',\n",
        "                 'done', 'try', 'many', 'some','nice', 'thank', 'think', 'see', 'rather',\n",
        "                  'easy', 'easily', 'lot', 'lack', 'make', 'want', 'seem', 'run', 'need', \n",
        "                   'even', 'right', 'line','even', 'also', 'may', 'take', 'come',\n",
        "                   'new','said', 'like','people'])\n",
        "  return [word for word in text if word not in stop_words]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnVZ6ynFIlS3"
      },
      "source": [
        "def stem_words(text):\n",
        "    \"\"\"\n",
        "    Function to stem words\n",
        "    \"\"\"\n",
        "    stemmer = PorterStemmer()\n",
        "    try:\n",
        "        text = [stemmer.stem(word) for word in text]\n",
        "        text = [word for word in text if len(word) > 1] # no single letter words\n",
        "    except IndexError:\n",
        "        pass\n",
        "\n",
        "    return text"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TG6ao15fI7ne"
      },
      "source": [
        "def apply_all(text):\n",
        "    \"\"\"\n",
        "    This function applies all the functions above into one\n",
        "    \"\"\"\n",
        "    return stem_words(remove_stop_words(initial_clean(text)))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(path):\n",
        "  # Import and clean data\n",
        "  reviews_df = import_data(path)\n",
        "  reviews_df['tokenized_reviews'] = reviews_df['Reviews'].apply(apply_all)\n",
        "\n",
        "  # Prepare the dictionary/corpus\n",
        "  tokenized = reviews_df['tokenized_reviews']\n",
        "  dictionary = corpora.Dictionary(tokenized)\n",
        "  dictionary.filter_extremes(no_below=1, no_above=0.8)\n",
        "  corpus = [dictionary.doc2bow(tokens) for tokens in tokenized]\n",
        "\n",
        "  return tokenized, dictionary, corpus\n"
      ],
      "metadata": {
        "id": "eouYwUnpfoHP"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "icp6_data_path = \"/content/drive/MyDrive/data/ICP-6/reviews.csv\"\n",
        "tokenized, dictionary, corpus = prepare_data(icp6_data_path)\n",
        "\n",
        "print(corpus[:1])\n",
        "print([[(dictionary[id], freq) for id, freq in cp] for cp in corpus[:1]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9v1ix02ziT_f",
        "outputId": "cfb33e8a-2c35-4618-d7e4-f9a22dda344a"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 2), (12, 1), (13, 1)]]\n",
            "[[('big', 1), ('comfort', 1), ('definit', 1), ('instead', 1), ('kindl', 1), ('palm', 1), ('paper', 1), ('paperwhit', 1), ('read', 1), ('recommend', 1), ('regular', 1), ('small', 2), ('thought', 1), ('turn', 1)]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling and Visualization Functions"
      ],
      "metadata": {
        "id": "rAe3RD05__no"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(tokenized, dictionary, corpus, **params):\n",
        "  # Build and save model\n",
        "  ldamodel = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=dictionary, **params)\n",
        "  ldamodel.save('model_combined.gensim')\n",
        "\n",
        "  # Calculate coherence\n",
        "  coherence_lda = []\n",
        "  for measure in [\"c_v\", \"c_uci\", \"u_mass\", \"c_npmi\"]:\n",
        "    coherence_model_lda = CoherenceModel(model=ldamodel, texts=tokenized, dictionary=dictionary, coherence=measure)\n",
        "    coherence_lda.append(coherence_model_lda.get_coherence())\n",
        "\n",
        "  coherence_avg = np.mean(coherence_lda)\n",
        "\n",
        "  return coherence_avg"
      ],
      "metadata": {
        "id": "aI-5M5rGihr_"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_lda_viz(model_path, dictionary, corpus):\n",
        "  lda_viz = gensim.models.ldamodel.LdaModel.load('/content/model_combined.gensim')\n",
        "  lda_display = pyLDAvis.gensim_models.prepare(lda_viz, corpus, dictionary, sort_topics=True)\n",
        "  \n",
        "  return lda_display"
      ],
      "metadata": {
        "id": "GmRrQbWOjo9e"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tuning Hyperparameters via Grid Search"
      ],
      "metadata": {
        "id": "pe_QwUx6AE9j"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhVHZAdYK7Tk",
        "outputId": "95ae3547-b6f0-4db8-dab6-322396a96727"
      },
      "source": [
        "t1 = time.time()\n",
        "coherence_avg_list = []\n",
        "i = 1\n",
        "for num_topics in [3, 7, 11, 15]:\n",
        "  for passes in [1, 5, 10, 15]:\n",
        "    for decay in [0.5, 0.67, 0.83, 1.0]:\n",
        "      params = {\n",
        "          \"alpha\": \"auto\",\n",
        "          \"eta\": \"auto\",\n",
        "          \"num_topics\": num_topics,\n",
        "          \"passes\": passes,\n",
        "          \"decay\": decay\n",
        "      }\n",
        "      coherence_avg = build_model(tokenized, dictionary, corpus, **params)\n",
        "      print(f\"PARAMETER SETTING {i}: (num_topics, passes, decay) = ({num_topics}, {passes}, {decay})\")\n",
        "      print(f\"-- Avg Coherence Score: {coherence_avg}\")\n",
        "\n",
        "      coherence_avg_list.append(coherence_avg)\n",
        "      i += 1\n",
        "\n",
        "      # # This will display the viz within the loop, but it's not ideal for 64 hyperparameter settings\n",
        "      # # The viz can be evaluated for the winning hyperparameter combination below\n",
        "      # model_path = \"/content/model_combined.gensim\"\n",
        "      # lda_display = run_lda_viz(model_path, dictionary, corpus)\n",
        "      # display(pyLDAvis.display(lda_display))\n",
        "\n",
        "print(f\"\\n\\n TOTAL TIME: {time.time() - t1}\")\n",
        "print(coherence_avg_list)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PARAMETER SETTING 1: (num_topics, passes, decay) = (3, 1, 0.5)\n",
            "-- Avg Coherence Score: -0.5352789331185692\n",
            "PARAMETER SETTING 2: (num_topics, passes, decay) = (3, 1, 0.67)\n",
            "-- Avg Coherence Score: -0.5201890329948292\n",
            "PARAMETER SETTING 3: (num_topics, passes, decay) = (3, 1, 0.83)\n",
            "-- Avg Coherence Score: -0.5633940528955523\n",
            "PARAMETER SETTING 4: (num_topics, passes, decay) = (3, 1, 1.0)\n",
            "-- Avg Coherence Score: -0.5315765616955025\n",
            "PARAMETER SETTING 5: (num_topics, passes, decay) = (3, 5, 0.5)\n",
            "-- Avg Coherence Score: -0.5245060190580774\n",
            "PARAMETER SETTING 6: (num_topics, passes, decay) = (3, 5, 0.67)\n",
            "-- Avg Coherence Score: -0.5791362249857772\n",
            "PARAMETER SETTING 7: (num_topics, passes, decay) = (3, 5, 0.83)\n",
            "-- Avg Coherence Score: -0.4840571419837106\n",
            "PARAMETER SETTING 8: (num_topics, passes, decay) = (3, 5, 1.0)\n",
            "-- Avg Coherence Score: -0.520224364597238\n",
            "PARAMETER SETTING 9: (num_topics, passes, decay) = (3, 10, 0.5)\n",
            "-- Avg Coherence Score: -0.4810832098731124\n",
            "PARAMETER SETTING 10: (num_topics, passes, decay) = (3, 10, 0.67)\n",
            "-- Avg Coherence Score: -0.4815070345637085\n",
            "PARAMETER SETTING 11: (num_topics, passes, decay) = (3, 10, 0.83)\n",
            "-- Avg Coherence Score: -0.4717976919038454\n",
            "PARAMETER SETTING 12: (num_topics, passes, decay) = (3, 10, 1.0)\n",
            "-- Avg Coherence Score: -0.4863361597665985\n",
            "PARAMETER SETTING 13: (num_topics, passes, decay) = (3, 15, 0.5)\n",
            "-- Avg Coherence Score: -0.47995339855508595\n",
            "PARAMETER SETTING 14: (num_topics, passes, decay) = (3, 15, 0.67)\n",
            "-- Avg Coherence Score: -0.4562766293979504\n",
            "PARAMETER SETTING 15: (num_topics, passes, decay) = (3, 15, 0.83)\n",
            "-- Avg Coherence Score: -0.4670329502729751\n",
            "PARAMETER SETTING 16: (num_topics, passes, decay) = (3, 15, 1.0)\n",
            "-- Avg Coherence Score: -0.5516509071309683\n",
            "PARAMETER SETTING 17: (num_topics, passes, decay) = (7, 1, 0.5)\n",
            "-- Avg Coherence Score: -0.6202796942471592\n",
            "PARAMETER SETTING 18: (num_topics, passes, decay) = (7, 1, 0.67)\n",
            "-- Avg Coherence Score: -0.5737386143975188\n",
            "PARAMETER SETTING 19: (num_topics, passes, decay) = (7, 1, 0.83)\n",
            "-- Avg Coherence Score: -0.5553708217133306\n",
            "PARAMETER SETTING 20: (num_topics, passes, decay) = (7, 1, 1.0)\n",
            "-- Avg Coherence Score: -0.599113124690623\n",
            "PARAMETER SETTING 21: (num_topics, passes, decay) = (7, 5, 0.5)\n",
            "-- Avg Coherence Score: -0.5380107376837137\n",
            "PARAMETER SETTING 22: (num_topics, passes, decay) = (7, 5, 0.67)\n",
            "-- Avg Coherence Score: -0.5308581780403429\n",
            "PARAMETER SETTING 23: (num_topics, passes, decay) = (7, 5, 0.83)\n",
            "-- Avg Coherence Score: -0.6262400584594096\n",
            "PARAMETER SETTING 24: (num_topics, passes, decay) = (7, 5, 1.0)\n",
            "-- Avg Coherence Score: -0.5260787688292027\n",
            "PARAMETER SETTING 25: (num_topics, passes, decay) = (7, 10, 0.5)\n",
            "-- Avg Coherence Score: -0.5311516067166556\n",
            "PARAMETER SETTING 26: (num_topics, passes, decay) = (7, 10, 0.67)\n",
            "-- Avg Coherence Score: -0.674595900028913\n",
            "PARAMETER SETTING 27: (num_topics, passes, decay) = (7, 10, 0.83)\n",
            "-- Avg Coherence Score: -0.5465452834811215\n",
            "PARAMETER SETTING 28: (num_topics, passes, decay) = (7, 10, 1.0)\n",
            "-- Avg Coherence Score: -0.5762746260153689\n",
            "PARAMETER SETTING 29: (num_topics, passes, decay) = (7, 15, 0.5)\n",
            "-- Avg Coherence Score: -0.6230865258904177\n",
            "PARAMETER SETTING 30: (num_topics, passes, decay) = (7, 15, 0.67)\n",
            "-- Avg Coherence Score: -0.5620308408475196\n",
            "PARAMETER SETTING 31: (num_topics, passes, decay) = (7, 15, 0.83)\n",
            "-- Avg Coherence Score: -0.5929732199411291\n",
            "PARAMETER SETTING 32: (num_topics, passes, decay) = (7, 15, 1.0)\n",
            "-- Avg Coherence Score: -0.5700203029802375\n",
            "PARAMETER SETTING 33: (num_topics, passes, decay) = (11, 1, 0.5)\n",
            "-- Avg Coherence Score: -0.8844971896496672\n",
            "PARAMETER SETTING 34: (num_topics, passes, decay) = (11, 1, 0.67)\n",
            "-- Avg Coherence Score: -0.7245838335431609\n",
            "PARAMETER SETTING 35: (num_topics, passes, decay) = (11, 1, 0.83)\n",
            "-- Avg Coherence Score: -0.7531481752307516\n",
            "PARAMETER SETTING 36: (num_topics, passes, decay) = (11, 1, 1.0)\n",
            "-- Avg Coherence Score: -0.6040558235115048\n",
            "PARAMETER SETTING 37: (num_topics, passes, decay) = (11, 5, 0.5)\n",
            "-- Avg Coherence Score: -0.7501700538011238\n",
            "PARAMETER SETTING 38: (num_topics, passes, decay) = (11, 5, 0.67)\n",
            "-- Avg Coherence Score: -0.818507181665569\n",
            "PARAMETER SETTING 39: (num_topics, passes, decay) = (11, 5, 0.83)\n",
            "-- Avg Coherence Score: -0.7292736304572509\n",
            "PARAMETER SETTING 40: (num_topics, passes, decay) = (11, 5, 1.0)\n",
            "-- Avg Coherence Score: -0.7486475490237603\n",
            "PARAMETER SETTING 41: (num_topics, passes, decay) = (11, 10, 0.5)\n",
            "-- Avg Coherence Score: -0.8592305270446555\n",
            "PARAMETER SETTING 42: (num_topics, passes, decay) = (11, 10, 0.67)\n",
            "-- Avg Coherence Score: -0.8565645200317039\n",
            "PARAMETER SETTING 43: (num_topics, passes, decay) = (11, 10, 0.83)\n",
            "-- Avg Coherence Score: -0.7431109297396185\n",
            "PARAMETER SETTING 44: (num_topics, passes, decay) = (11, 10, 1.0)\n",
            "-- Avg Coherence Score: -0.7633210290056811\n",
            "PARAMETER SETTING 45: (num_topics, passes, decay) = (11, 15, 0.5)\n",
            "-- Avg Coherence Score: -0.9539698776193309\n",
            "PARAMETER SETTING 46: (num_topics, passes, decay) = (11, 15, 0.67)\n",
            "-- Avg Coherence Score: -0.704665172127568\n",
            "PARAMETER SETTING 47: (num_topics, passes, decay) = (11, 15, 0.83)\n",
            "-- Avg Coherence Score: -0.8390551651743284\n",
            "PARAMETER SETTING 48: (num_topics, passes, decay) = (11, 15, 1.0)\n",
            "-- Avg Coherence Score: -0.6502663201917932\n",
            "PARAMETER SETTING 49: (num_topics, passes, decay) = (15, 1, 0.5)\n",
            "-- Avg Coherence Score: -0.9101820628938909\n",
            "PARAMETER SETTING 50: (num_topics, passes, decay) = (15, 1, 0.67)\n",
            "-- Avg Coherence Score: -0.9965958629137145\n",
            "PARAMETER SETTING 51: (num_topics, passes, decay) = (15, 1, 0.83)\n",
            "-- Avg Coherence Score: -0.8003882923671807\n",
            "PARAMETER SETTING 52: (num_topics, passes, decay) = (15, 1, 1.0)\n",
            "-- Avg Coherence Score: -0.7977125505709041\n",
            "PARAMETER SETTING 53: (num_topics, passes, decay) = (15, 5, 0.5)\n",
            "-- Avg Coherence Score: -1.0408959208701707\n",
            "PARAMETER SETTING 54: (num_topics, passes, decay) = (15, 5, 0.67)\n",
            "-- Avg Coherence Score: -1.0572979178025348\n",
            "PARAMETER SETTING 55: (num_topics, passes, decay) = (15, 5, 0.83)\n",
            "-- Avg Coherence Score: -1.1603233965995334\n",
            "PARAMETER SETTING 56: (num_topics, passes, decay) = (15, 5, 1.0)\n",
            "-- Avg Coherence Score: -0.8495181421661634\n",
            "PARAMETER SETTING 57: (num_topics, passes, decay) = (15, 10, 0.5)\n",
            "-- Avg Coherence Score: -1.0539272077028166\n",
            "PARAMETER SETTING 58: (num_topics, passes, decay) = (15, 10, 0.67)\n",
            "-- Avg Coherence Score: -0.9765680521155184\n",
            "PARAMETER SETTING 59: (num_topics, passes, decay) = (15, 10, 0.83)\n",
            "-- Avg Coherence Score: -1.0779717100764732\n",
            "PARAMETER SETTING 60: (num_topics, passes, decay) = (15, 10, 1.0)\n",
            "-- Avg Coherence Score: -0.9705463114300479\n",
            "PARAMETER SETTING 61: (num_topics, passes, decay) = (15, 15, 0.5)\n",
            "-- Avg Coherence Score: -0.963964673439625\n",
            "PARAMETER SETTING 62: (num_topics, passes, decay) = (15, 15, 0.67)\n",
            "-- Avg Coherence Score: -0.9740286829405891\n",
            "PARAMETER SETTING 63: (num_topics, passes, decay) = (15, 15, 0.83)\n",
            "-- Avg Coherence Score: -0.8613950083072911\n",
            "PARAMETER SETTING 64: (num_topics, passes, decay) = (15, 15, 1.0)\n",
            "-- Avg Coherence Score: -0.764662544849434\n",
            "\n",
            "\n",
            " TOTAL TIME: 1157.0447328090668\n",
            "[-0.5352789331185692, -0.5201890329948292, -0.5633940528955523, -0.5315765616955025, -0.5245060190580774, -0.5791362249857772, -0.4840571419837106, -0.520224364597238, -0.4810832098731124, -0.4815070345637085, -0.4717976919038454, -0.4863361597665985, -0.47995339855508595, -0.4562766293979504, -0.4670329502729751, -0.5516509071309683, -0.6202796942471592, -0.5737386143975188, -0.5553708217133306, -0.599113124690623, -0.5380107376837137, -0.5308581780403429, -0.6262400584594096, -0.5260787688292027, -0.5311516067166556, -0.674595900028913, -0.5465452834811215, -0.5762746260153689, -0.6230865258904177, -0.5620308408475196, -0.5929732199411291, -0.5700203029802375, -0.8844971896496672, -0.7245838335431609, -0.7531481752307516, -0.6040558235115048, -0.7501700538011238, -0.818507181665569, -0.7292736304572509, -0.7486475490237603, -0.8592305270446555, -0.8565645200317039, -0.7431109297396185, -0.7633210290056811, -0.9539698776193309, -0.704665172127568, -0.8390551651743284, -0.6502663201917932, -0.9101820628938909, -0.9965958629137145, -0.8003882923671807, -0.7977125505709041, -1.0408959208701707, -1.0572979178025348, -1.1603233965995334, -0.8495181421661634, -1.0539272077028166, -0.9765680521155184, -1.0779717100764732, -0.9705463114300479, -0.963964673439625, -0.9740286829405891, -0.8613950083072911, -0.764662544849434]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Find and Output Best Results"
      ],
      "metadata": {
        "id": "iJeEFbSBANSV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = np.max(coherence_avg_list)\n",
        "(coherence_avg_list.index(m)+1, m)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5FLFSlEbhFY",
        "outputId": "28a0efaf-a4b9-412e-c6fe-7bdb64cde24f"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14, -0.4562766293979504)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_best_model(tokenized, dictionary, corpus, num_topics, passes, decay):\n",
        "  params = {\n",
        "          \"alpha\": \"auto\",\n",
        "          \"eta\": \"auto\",\n",
        "          \"num_topics\": num_topics,\n",
        "          \"passes\": passes,\n",
        "          \"decay\": decay\n",
        "      }\n",
        "  coherence_score = build_model(tokenized, dictionary, corpus, **params)\n",
        "  print(f\"PARAMETER SETTING: (num_topics, passes, decay) = ({num_topics}, {passes}, {decay})\")\n",
        "  print(f\"-- Coherence Score: {coherence_score}\")\n",
        "\n",
        "  model_path = \"/content/model_combined.gensim\"\n",
        "  lda_display = run_lda_viz(model_path, dictionary, corpus)\n",
        "  display(pyLDAvis.display(lda_display))"
      ],
      "metadata": {
        "id": "E5qEpztu6boC"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_topics = 3\n",
        "passes = 15\n",
        "decay = 0.67\n",
        "\n",
        "run_best_model(tokenized, dictionary, corpus, num_topics, passes, decay)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 896
        },
        "id": "HzqNGoOk6bkt",
        "outputId": "96f2054d-c4d1-4fd0-af45-2e4c9b00f0c5"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PARAMETER SETTING: (num_topics, passes, decay) = (3, 15, 0.67)\n",
            "-- Coherence Score: -0.4782219605768235\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el731406510182510884166399535\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el731406510182510884166399535_data = {\"mdsDat\": {\"x\": [0.1067389968943496, -0.014476392564459695, -0.09226260432988992], \"y\": [0.0378560314818077, -0.09684763803117807, 0.05899160654937039], \"topics\": [1, 2, 3], \"cluster\": [1, 1, 1], \"Freq\": [35.64427549104219, 32.51146476177271, 31.844259747185106]}, \"tinfo\": {\"Term\": [\"echo\", \"tablet\", \"love\", \"alexa\", \"gift\", \"old\", \"bought\", \"kid\", \"kindl\", \"game\", \"music\", \"son\", \"show\", \"sound\", \"christma\", \"daughter\", \"smart\", \"grandson\", \"one\", \"speaker\", \"dot\", \"great\", \"fire\", \"home\", \"parent\", \"granddaught\", \"hous\", \"charg\", \"light\", \"purchas\", \"echo\", \"smart\", \"dot\", \"recip\", \"kitchen\", \"voic\", \"bulb\", \"hub\", \"junk\", \"lyric\", \"ring\", \"autom\", \"cell\", \"cook\", \"bedroom\", \"doorbel\", \"alexa\", \"command\", \"alarm\", \"thermostat\", \"arlo\", \"brief\", \"variou\", \"philip\", \"pandora\", \"cam\", \"phillip\", \"hue\", \"morn\", \"versatil\", \"hous\", \"answer\", \"weather\", \"tap\", \"sound\", \"music\", \"question\", \"speaker\", \"show\", \"ask\", \"listen\", \"home\", \"room\", \"list\", \"plu\", \"video\", \"light\", \"product\", \"great\", \"devic\", \"famili\", \"work\", \"use\", \"set\", \"love\", \"amazon\", \"fun\", \"thing\", \"connect\", \"buy\", \"screen\", \"play\", \"read\", \"well\", \"book\", \"purchas\", \"one\", \"bought\", \"much\", \"oasi\", \"voyag\", \"paperwhit\", \"magazin\", \"pocket\", \"tag\", \"menu\", \"font\", \"inexpens\", \"keyboard\", \"audibl\", \"clariti\", \"sunlight\", \"comfort\", \"browser\", \"swipe\", \"bad\", \"bottom\", \"left\", \"biggest\", \"often\", \"drain\", \"page\", \"imag\", \"silk\", \"curiou\", \"spec\", \"lighter\", \"edg\", \"android\", \"os\", \"appear\", \"spent\", \"charg\", \"purs\", \"button\", \"charger\", \"eread\", \"ok\", \"kindl\", \"cover\", \"model\", \"ipad\", \"batteri\", \"store\", \"fit\", \"ebook\", \"app\", \"read\", \"hold\", \"reader\", \"screen\", \"version\", \"book\", \"fire\", \"tablet\", \"size\", \"amazon\", \"hand\", \"dont\", \"price\", \"better\", \"devic\", \"life\", \"look\", \"small\", \"one\", \"littl\", \"best\", \"great\", \"much\", \"im\", \"light\", \"work\", \"use\", \"download\", \"well\", \"love\", \"realli\", \"bought\", \"grandson\", \"granddaught\", \"yr\", \"birthday\", \"parent\", \"niec\", \"age\", \"grand\", \"nephew\", \"law\", \"educ\", \"teenag\", \"son\", \"father\", \"appropri\", \"young\", \"broke\", \"crack\", \"nexu\", \"recipi\", \"he\", \"pink\", \"durabl\", \"four\", \"tough\", \"gift\", \"boy\", \"youngest\", \"prior\", \"teach\", \"children\", \"friendli\", \"present\", \"old\", \"christma\", \"daughter\", \"mom\", \"game\", \"kid\", \"bought\", \"love\", \"tablet\", \"protect\", \"mother\", \"one\", \"user\", \"purchas\", \"got\", \"perfect\", \"great\", \"wife\", \"play\", \"price\", \"fire\", \"movi\", \"kindl\", \"learn\", \"work\", \"watch\", \"app\", \"use\", \"amazon\", \"product\", \"read\", \"buy\", \"well\", \"realli\", \"book\", \"set\"], \"Freq\": [556.0, 1478.0, 1592.0, 404.0, 300.0, 388.0, 779.0, 446.0, 840.0, 409.0, 359.0, 188.0, 356.0, 289.0, 188.0, 197.0, 132.0, 115.0, 832.0, 198.0, 109.0, 1605.0, 480.0, 232.0, 89.0, 87.0, 113.0, 164.0, 347.0, 549.0, 551.8173901758826, 131.0166019178573, 107.78391916747195, 51.132586696368854, 55.85235729967872, 61.18860697049566, 54.26666791342304, 52.18578228028822, 25.834807725700134, 27.649964002709567, 22.44326214669786, 25.84754047749795, 22.092618231816637, 21.260837567157054, 19.92391292521082, 17.274293899287073, 391.9094910405764, 30.81990451468772, 25.107819924422127, 14.448459364398609, 18.789848783836746, 15.954003612513485, 14.146440378935246, 15.071413463669922, 14.001110299690744, 12.078663504079577, 13.717346929285355, 49.45012496521193, 15.084811017801668, 13.229713702506185, 108.13596417114297, 47.184001097242636, 69.6461908097446, 96.79048471203012, 257.9560240199697, 310.6387467597121, 74.17565924302262, 173.74652745553695, 303.867930855125, 109.6808790142509, 97.18789068011176, 184.27148356951142, 76.58724186165588, 37.169664644294485, 123.61989391658769, 186.29974545144773, 211.32387748464632, 287.5266377074651, 680.5840608090697, 242.8066285276885, 107.1141987259529, 297.039218530506, 244.7192691314536, 177.77004271126808, 472.89201134182713, 252.31605261190504, 98.08713805904699, 142.55659825083086, 102.04919984483908, 158.30618586827904, 171.5001189083954, 170.72467059117994, 191.80762563964893, 143.53118417554845, 154.40455961852976, 152.0817488418716, 164.1958484548733, 131.87581818851285, 118.02900064727393, 58.34205532892215, 47.42314637961019, 53.438071691738, 38.422287884490636, 17.251643710277502, 14.82309176318587, 18.728439072483972, 15.014293305265449, 23.997986903107655, 14.400748963626684, 12.73814681585787, 18.365194741709203, 12.193273799564565, 25.707552251556127, 16.25643827540496, 13.611635746364376, 30.5644918384343, 13.867888636972435, 17.261953341659, 12.461488522788677, 20.52155468557248, 9.558132800868725, 67.11029640886872, 10.522121803812851, 9.699686804272337, 8.254368027227349, 9.126846989418022, 24.251549587601367, 8.160530299651736, 46.896220676332774, 24.908773591870382, 24.68166177544426, 14.820685834789858, 135.13540373144872, 27.017047568469195, 63.46657066617129, 26.95110557002501, 50.761203157679574, 36.798271872894176, 493.6972371162978, 65.14596345568918, 65.23173186894799, 108.17974189377294, 136.9284085023076, 104.34383919737523, 52.64808216884853, 49.62710197687511, 267.96894036011156, 341.54433280043474, 58.80799954953773, 81.13711193870594, 245.08309222802757, 63.057847116567636, 233.4982066503848, 219.7183215276309, 506.84707935753954, 138.32491627350376, 284.96826803497214, 66.33630989588485, 100.714984569815, 196.39484219245662, 127.84474955763078, 159.83156367052814, 79.00145601931068, 109.12991799886626, 78.06932242114812, 207.36182798084943, 102.37300697746089, 125.19420670512177, 267.65219760473076, 125.82902753874392, 100.98087030219072, 119.62116372159696, 148.4632194726838, 122.74034230486212, 85.64618948822906, 101.54467908338293, 138.372487150407, 96.88549768247331, 106.71819972638933, 114.17108457035263, 85.85660663168125, 59.4671609129855, 45.08575175055483, 87.68212459541549, 28.2851417204078, 54.95308736835578, 24.111704483734908, 35.59638433671419, 19.14876304254676, 37.74613086459586, 13.432009284824806, 181.24978327569445, 14.349497978300692, 13.31496967806117, 20.11046936664208, 13.490432654713116, 16.556639677894864, 9.972861320892651, 11.591883243405059, 10.96923325069081, 9.394842792597789, 45.13921805569736, 11.965015722776991, 10.44497160528382, 283.3346933374791, 11.295686810145419, 7.2538250924596355, 8.207358837638216, 7.795638272317559, 73.11857236135208, 67.38971268771658, 42.80441629240548, 330.9482849918278, 162.52246525413491, 168.7885220725881, 61.034834874050524, 324.5614500124984, 349.4446122261819, 540.9004770757084, 981.1063008588789, 896.1316098183198, 41.31609623974694, 38.25041289513921, 460.7320211334892, 65.31584846247509, 305.6727470270743, 175.35417412597278, 164.66757531073932, 657.1504582946724, 110.65252654946282, 252.45461954709194, 246.29936800584196, 215.76650588267756, 96.7031700923053, 282.0330889644899, 96.09560076525798, 205.0588168708241, 112.51794626600768, 159.89156540697414, 160.75732615272028, 165.8316642447208, 147.87304506111016, 154.88959203031416, 127.83568250066597, 123.8592914614835, 119.17709410382699, 125.65261213376927, 116.97579461349517], \"Total\": [556.0, 1478.0, 1592.0, 404.0, 300.0, 388.0, 779.0, 446.0, 840.0, 409.0, 359.0, 188.0, 356.0, 289.0, 188.0, 197.0, 132.0, 115.0, 832.0, 198.0, 109.0, 1605.0, 480.0, 232.0, 89.0, 87.0, 113.0, 164.0, 347.0, 549.0, 556.7658199441476, 132.6518745127754, 109.392815895845, 51.96907531796926, 56.78188657562525, 62.294816055789404, 55.249002179196204, 53.15059882597305, 26.387414045762718, 28.364335622442503, 23.023628978546473, 26.538859931049224, 22.73952849727716, 21.896634105949197, 20.534685090483258, 17.824934849920282, 404.76725945223615, 31.854517451905544, 25.982845160583036, 14.972682329357308, 19.485413389317287, 16.549069648242448, 14.683434818291717, 15.645736148753196, 14.55145143000269, 12.555442166623823, 14.267268127071533, 51.43509729106387, 15.69697374608974, 13.791996723488525, 113.7942868252907, 49.27984598568751, 73.69020137691926, 103.29817618256295, 289.0211292044097, 359.3290289777944, 81.70354069930669, 198.3842458879474, 356.3320313411563, 124.00300752481033, 110.5270913018538, 232.96280293563854, 90.04409419075752, 40.69664776143425, 167.61351829008626, 294.06616690973175, 347.75944569638887, 534.118703924954, 1605.3867167084727, 439.9126725937546, 162.2066561459287, 650.5612548740139, 528.216937589036, 336.42701194679285, 1592.370799351113, 703.1159848915979, 145.86431965738535, 283.2331743383932, 157.85055135159968, 382.5877631606669, 492.4991824771183, 502.03576452123104, 688.2415504703978, 368.93515472041486, 513.5553784026838, 549.7652305340171, 832.289697569212, 779.4944949906105, 357.58546248658, 59.251311972408054, 48.28011012677449, 54.58252662348764, 39.5953129007697, 17.835856933013126, 15.377128007064565, 19.471679542122587, 15.650938132938963, 25.019503383878185, 15.015211705958311, 13.28287327347537, 19.172337757164044, 12.73169695430073, 26.86149487471415, 17.016161409476698, 14.253735309304762, 32.058457034890424, 14.55488883973294, 18.13208129962103, 13.0926097826076, 21.56554713578723, 10.053093347468808, 70.6347906025281, 11.07817065140068, 10.246962262872058, 8.72519775227398, 9.65552501116566, 25.664688280668788, 8.649612459914394, 49.737034061085744, 26.70773031887561, 26.690871186342846, 15.979284868469707, 164.88068617161468, 30.155831567056982, 75.65494849266138, 30.41735740139335, 61.13217672099191, 43.85544765135617, 840.9150441540321, 84.7497898536345, 85.16937529676552, 153.01592484951817, 204.12619836905856, 149.87120654055616, 68.65084512841429, 64.16894348805448, 509.23099041359376, 688.2415504703978, 80.11903117111697, 119.83489048790422, 492.4991824771183, 88.61261391066022, 513.5553784026838, 480.86479801927857, 1478.6983482652292, 263.43475169512703, 703.1159848915979, 101.0638668321407, 191.04521775302047, 532.1832552280349, 301.5864018458448, 439.9126725937546, 135.6916464054528, 242.45410724275914, 134.51797634936347, 832.289697569212, 223.41842707844341, 338.5081533143515, 1605.3867167084727, 357.58546248658, 226.44195027024028, 347.75944569638887, 650.5612548740139, 528.216937589036, 178.2684392260892, 368.93515472041486, 1592.370799351113, 325.3525727469299, 779.4944949906105, 115.96771411143519, 87.27308793491079, 60.55287039435943, 45.9880650406453, 89.61998747871696, 28.985244679290325, 56.36909284278745, 24.863762771460777, 36.730801439300386, 19.845609258439872, 39.15758649088792, 13.954488111149404, 188.30307227443242, 14.913390829536386, 13.869490393184847, 20.948117613019075, 14.069397726465235, 17.273752780283793, 10.424848943131913, 12.165170877132518, 11.512502402085246, 9.902448861001785, 47.687129943108616, 12.648332238852968, 11.05345656434587, 300.152958991272, 12.001643684855633, 7.720225984017413, 8.75399017788947, 8.316094849478787, 78.2057638402358, 72.27140529072759, 45.819024496033386, 388.2241335765529, 188.26824923444468, 197.22374861129148, 68.87663811147402, 409.439579567643, 446.6184380365827, 779.4944949906105, 1592.370799351113, 1478.6983482652292, 48.450016470945116, 44.70986309854926, 832.289697569212, 85.42353376541062, 549.7652305340171, 295.91801604524653, 274.3642335210898, 1605.3867167084727, 169.0732404027744, 502.03576452123104, 532.1832552280349, 480.86479801927857, 156.5200432836575, 840.9150441540321, 163.08199662237467, 650.5612548740139, 222.49672704735667, 509.23099041359376, 528.216937589036, 703.1159848915979, 534.118703924954, 688.2415504703978, 382.5877631606669, 368.93515472041486, 325.3525727469299, 513.5553784026838, 336.42701194679285], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.7957, -5.2336, -5.4288, -6.1745, -6.0862, -5.995, -6.115, -6.1541, -6.8572, -6.7893, -6.998, -6.8567, -7.0137, -7.0521, -7.117, -7.2597, -4.1379, -6.6808, -6.8858, -7.4384, -7.1756, -7.3392, -7.4595, -7.3961, -7.4698, -7.6175, -7.4903, -6.208, -7.3953, -7.5265, -5.4256, -6.2549, -5.8655, -5.5364, -4.5562, -4.3703, -5.8025, -4.9513, -4.3924, -5.4114, -5.5323, -4.8925, -5.7705, -6.4935, -5.2917, -4.8816, -4.7556, -4.4476, -3.586, -4.6167, -5.4351, -4.4151, -4.6088, -4.9285, -3.9501, -4.5783, -5.5231, -5.1492, -5.4835, -5.0444, -4.9644, -4.9689, -4.8525, -5.1424, -5.0694, -5.0845, -5.0079, -5.2271, -5.338, -5.9506, -6.1578, -6.0384, -6.3683, -7.169, -7.3208, -7.0869, -7.3079, -6.839, -7.3497, -7.4723, -7.1065, -7.5161, -6.7702, -7.2285, -7.406, -6.5971, -7.3874, -7.1684, -7.4943, -6.9955, -7.7596, -5.8106, -7.6635, -7.7449, -7.9062, -7.8057, -6.8285, -7.9176, -6.169, -6.8017, -6.8109, -7.3209, -5.1107, -6.7205, -5.8664, -6.7229, -6.0898, -6.4115, -3.815, -5.8403, -5.839, -5.3332, -5.0975, -5.3693, -6.0533, -6.1124, -4.4261, -4.1835, -5.9427, -5.6208, -4.5154, -5.8729, -4.5638, -4.6246, -3.7887, -5.0873, -4.3646, -5.8222, -5.4047, -4.7368, -5.1661, -4.9428, -5.6475, -5.3244, -5.6594, -4.6825, -5.3883, -5.1871, -4.4273, -5.182, -5.402, -5.2326, -5.0166, -5.2069, -5.5667, -5.3965, -5.087, -5.4434, -5.3468, -5.2585, -5.5435, -5.9108, -6.1876, -5.5225, -6.6539, -5.9897, -6.8135, -6.424, -7.044, -6.3653, -7.3986, -4.7963, -7.3325, -7.4073, -6.995, -7.3942, -7.1894, -7.6963, -7.5459, -7.6011, -7.7561, -6.1865, -7.5142, -7.6501, -4.3496, -7.5718, -8.0147, -7.8912, -7.9427, -5.7041, -5.7857, -6.2396, -4.1943, -4.9054, -4.8676, -5.8848, -4.2137, -4.1399, -3.703, -3.1075, -3.1981, -6.275, -6.3521, -3.8634, -5.817, -4.2737, -4.8294, -4.8923, -3.5083, -5.2898, -4.465, -4.4897, -4.622, -5.4246, -4.3542, -5.4309, -4.6729, -5.2731, -4.9217, -4.9163, -4.8852, -4.9999, -4.9535, -5.1455, -5.1771, -5.2156, -5.1627, -5.2342], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.0227, 1.0192, 1.0168, 1.0154, 1.0151, 1.0137, 1.0136, 1.0133, 1.0104, 1.0061, 1.0061, 1.0052, 1.0027, 1.0021, 1.0014, 1.0002, 0.9993, 0.9986, 0.9973, 0.9959, 0.9952, 0.995, 0.9943, 0.9942, 0.993, 0.9929, 0.9923, 0.9922, 0.9918, 0.99, 0.9806, 0.9881, 0.9751, 0.9665, 0.9179, 0.886, 0.9349, 0.899, 0.8723, 0.9089, 0.903, 0.7971, 0.8697, 0.9409, 0.7271, 0.5751, 0.5335, 0.4123, 0.1734, 0.4373, 0.6166, 0.2476, 0.2622, 0.3937, -0.1825, 0.0067, 0.6348, 0.3451, 0.5954, 0.1492, -0.0233, -0.047, -0.2461, 0.0875, -0.1702, -0.2535, -0.5915, -0.7452, -0.0769, 1.1081, 1.1057, 1.1024, 1.0935, 1.0903, 1.0869, 1.0847, 1.082, 1.0819, 1.0818, 1.0817, 1.0806, 1.0804, 1.0797, 1.0779, 1.0775, 1.0759, 1.0752, 1.0744, 1.0742, 1.074, 1.0731, 1.0724, 1.0721, 1.0687, 1.0681, 1.0673, 1.0669, 1.0654, 1.0648, 1.0538, 1.0453, 1.0483, 0.9246, 1.0137, 0.9479, 1.0026, 0.9377, 0.9481, 0.591, 0.8605, 0.8569, 0.7768, 0.7243, 0.7615, 0.8582, 0.8666, 0.4815, 0.4229, 0.8143, 0.7336, 0.4257, 0.7834, 0.3354, 0.3403, 0.0529, 0.4794, 0.2204, 0.7026, 0.4834, 0.1267, 0.2653, 0.1111, 0.5827, 0.3253, 0.5795, -0.2661, 0.3432, 0.1289, -0.6679, 0.0791, 0.316, 0.0564, -0.3539, -0.3359, 0.3905, -0.1665, -1.3195, -0.0878, -0.8649, 1.1287, 1.1279, 1.1262, 1.1245, 1.1225, 1.1199, 1.1189, 1.1136, 1.1129, 1.1086, 1.1076, 1.1062, 1.1061, 1.1058, 1.1035, 1.1035, 1.1023, 1.1019, 1.1, 1.096, 1.096, 1.0917, 1.0894, 1.0888, 1.0877, 1.0866, 1.0837, 1.082, 1.0798, 1.0797, 1.0771, 1.0744, 1.0763, 0.9847, 0.9973, 0.9886, 1.0234, 0.912, 0.899, 0.7789, 0.66, 0.6435, 0.985, 0.9883, 0.5529, 0.8759, 0.5573, 0.621, 0.6338, 0.2511, 0.7204, 0.4569, 0.3739, 0.3429, 0.6628, 0.0518, 0.6154, -0.0102, 0.4625, -0.0141, -0.0453, -0.3002, -0.14, -0.3471, 0.0481, 0.0528, 0.14, -0.2635, 0.0879]}, \"token.table\": {\"Topic\": [1, 2, 3, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 3, 1, 1, 2, 3, 2, 1, 1, 2, 3, 1, 2, 3, 1, 1, 2, 3, 1, 2, 3, 2, 1, 3, 1, 2, 3, 2, 1, 2, 3, 3, 1, 3, 2, 1, 3, 1, 2, 3, 1, 2, 3, 1, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 1, 2, 1, 2, 1, 2, 3, 1, 1, 2, 3, 3, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 1, 2, 3, 1, 2, 3, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 3, 1, 2, 3, 1, 2, 3, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 1, 2, 3, 1, 2, 3, 2, 2, 3, 1, 2, 3, 1, 2, 1, 2, 3, 1, 2, 3, 1, 3, 1, 2, 3, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 1, 2, 2, 1, 2, 3, 1, 2, 3, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 3, 3, 1, 2, 1, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 1, 3, 1, 2, 3, 1, 2, 3, 2, 1, 2, 3, 1, 2, 3, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 3, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 1, 2, 3, 1, 2, 3, 2, 2, 1, 2, 3, 2, 1, 2, 3, 3, 3, 1, 1, 2, 3, 3, 1, 2, 3, 1, 2, 3, 1, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 3, 3, 1, 3], \"Freq\": [0.017740218079950035, 0.017740218079950035, 0.9757119943972519, 0.9621733049437539, 0.9684577762798458, 0.019764444413874403, 0.012352777758671503, 0.3584045952800402, 0.4053385303762359, 0.23609191593843917, 0.04021148501825926, 0.9449698979290927, 0.02010574250912963, 0.9537367469380962, 0.020292271211448856, 0.020292271211448856, 0.1590633750200717, 0.5262837593256693, 0.3141992592989071, 0.037465993261084664, 0.9366498315271167, 0.037465993261084664, 0.9373091318761001, 0.9750883709973835, 0.8870752588641156, 0.056450243745898264, 0.06451456428102659, 0.9787039093386337, 0.9796954378428749, 0.031193017147134138, 0.9669835315611582, 0.031193017147134138, 0.14696790632312778, 0.671153438875617, 0.1861593480092952, 0.9739618558489093, 0.34268007687329766, 0.3692673242169156, 0.2865514435923265, 0.3647379302473533, 0.4244223188332838, 0.2122111594166419, 0.9165475943490627, 0.02174477223854009, 0.978514750734304, 0.2998702895079936, 0.4536998536062501, 0.2453484186883584, 0.9618761197118754, 0.16934051599888467, 0.13726844857485349, 0.6940395390560349, 0.9165411246028271, 0.9668217211049831, 0.9239912221364213, 0.940282571079117, 0.9773932174350379, 0.018099874396945145, 0.14539696634737664, 0.8327280799895208, 0.013217906031579695, 0.4129771394012104, 0.2509228188766848, 0.3345637585022464, 0.9557608438434484, 0.9674782835815742, 0.12129983483440362, 0.8187738851322245, 0.06064991741720181, 0.03287596574560393, 0.8876510751313061, 0.06575193149120787, 0.03836034395276299, 0.025573562635175327, 0.9334350361838994, 0.11154297171930114, 0.026557850409357413, 0.8657859233450517, 0.9388526442621228, 0.037228010007043275, 0.9679282601831252, 0.9731743714782147, 0.03139272166058757, 0.6461808281733716, 0.29141488329387344, 0.06335106158562466, 0.9590515098525766, 0.07079663572455089, 0.7669635536826346, 0.1533927107365269, 0.9841520957393662, 0.9168846629195336, 0.04563344963966845, 0.10140766586592989, 0.8568947765671076, 0.5523823593606788, 0.36370854937328645, 0.08410760204257249, 0.25124941919275606, 0.5286706528847576, 0.22507760469351062, 0.9537201758735195, 0.9872677571699852, 0.009141368121944307, 0.009141368121944307, 0.10097132211479944, 0.48241853899293063, 0.42071384214499763, 0.9947187054139733, 0.041940037120833794, 0.020970018560416897, 0.9436508352187604, 0.15583862623297784, 0.7791931311648892, 0.06233545049319114, 0.9914401714806673, 0.003592174534350244, 0.005388261801525366, 0.9248969288595361, 0.025537835439186293, 0.025537835439186293, 0.9704377466890791, 0.06543199039445388, 0.834257877529287, 0.09814798559168084, 0.6596523382106946, 0.08630965172850211, 0.25276398006204187, 0.9387536449640017, 0.09358139790094572, 0.45750905640462347, 0.4491907099245394, 0.08739877839488717, 0.77202254248817, 0.14566463065814528, 0.9584090022329717, 0.9487416817798769, 0.05534692433209403, 0.013836731083023508, 0.9270609825625751, 0.6718572453509407, 0.0891239203016554, 0.23309333001971413, 0.06838615853789033, 0.13921467988070532, 0.7937679116005129, 0.03997961586095489, 0.01665817327539787, 0.9428526073875195, 0.23317269060579854, 0.1723450321868946, 0.5913800124060108, 0.9652601748415881, 0.011458285980963694, 0.011458285980963694, 0.9854125943628776, 0.008623089690627897, 0.008623089690627897, 0.9830322247315803, 0.42419685731314355, 0.16693797027888763, 0.40924718833294466, 0.2671577968102578, 0.6530523922028524, 0.07915786572155788, 0.9554829711051859, 0.07488857406656971, 0.7364043116546021, 0.18722143516642425, 0.7898256617853037, 0.1631161692817475, 0.042925307705723025, 0.9490810392424471, 0.03515114960157211, 0.017575574800786056, 0.9783521004205359, 0.9526568934577104, 0.019441977417504294, 0.019441977417504294, 0.30912999961562165, 0.4460304280168256, 0.2428878568408456, 0.9929437220403536, 0.9592516538703513, 0.039968818911264636, 0.052282139965938265, 0.7058088895401665, 0.2352696298467222, 0.9853182261402789, 0.9323877860772715, 0.0671714319092726, 0.1500161979307088, 0.7814276578778713, 0.07729675007228652, 0.5874553005493776, 0.3353489772366892, 0.9862300000443999, 0.9573906123300169, 0.2943304656193696, 0.11650580930766714, 0.5886609312387392, 0.9375647350729288, 0.25056811455000305, 0.58220238380736, 0.1695019598426491, 0.6067412477538091, 0.3450661124666213, 0.04888436593277135, 0.03896404230840482, 0.9351370154017157, 0.03896404230840482, 0.9091657921530987, 0.024572048436570234, 0.0737161453097107, 0.877612889812591, 0.10857066678093909, 0.018095111130156515, 0.21484351415269315, 0.4565424675744729, 0.3267411777738875, 0.3423328272055032, 0.44956961645060056, 0.20622459470211035, 0.29704136762162825, 0.08666323199108816, 0.6160625404583876, 0.9871551504927818, 0.025255514522794967, 0.9597095518662088, 0.9757761244425672, 0.10567178599866744, 0.7631851211014871, 0.12915440510948242, 0.08711226570450847, 0.029037421901502825, 0.8856413679958361, 0.9555982090966189, 0.1341985768727323, 0.022366429478788714, 0.8499243201939711, 0.1852797852058091, 0.19805770142689938, 0.6197289367228787, 0.3299910437618209, 0.35236331791516473, 0.31880490668514905, 0.8655020188174638, 0.07514004664974766, 0.05844225850535929, 0.027225107016860317, 0.027225107016860317, 0.9801038526069714, 0.9592465132636947, 0.9660087506525596, 0.016877263417655233, 0.9788812782240035, 0.04637025871421258, 0.9737754329984641, 0.045604368604322126, 0.8436808191799594, 0.11401092151080532, 0.051516632455968256, 0.09788160166633968, 0.8526002671462746, 0.19704677407275248, 0.24871147703085222, 0.5538936758996273, 0.037442343024306074, 0.9360585756076519, 0.037442343024306074, 0.014157329433127941, 0.948541072019572, 0.028314658866255882, 0.962103338443223, 0.018320881458970165, 0.9710067173254187, 0.018320881458970165, 0.01115822516977567, 0.01115822516977567, 0.9819238149402589, 0.17859470737549135, 0.21868739678631594, 0.6013903411623688, 0.9587276595608029, 0.9812670425276158, 0.9088660922495804, 0.34061318353100806, 0.15735930701140138, 0.5019562704667486, 0.7397971313113004, 0.14318654154412266, 0.11932211795343554, 0.9531361494907484, 0.04364999084983013, 0.021824995424915065, 0.9384748032713478, 0.16723562631046038, 0.3682941882792161, 0.46224678733003655, 0.9138689714555686, 0.53920598152366, 0.18535205614875813, 0.2770919627274364, 0.04127965572930972, 0.1031991393232743, 0.8462329424508493, 0.27648165354574, 0.16734415872505318, 0.5566012235855029, 0.06632216377627113, 0.8953492109796602, 0.03316108188813557, 0.9057135023357432, 0.0611968582659286, 0.03671811495955716, 0.2789718230013464, 0.49691855972114823, 0.22521162794379523, 0.2586892671557041, 0.6759300206326463, 0.06675852055631074, 0.33502117127803943, 0.2981381065501819, 0.36575705855125407, 0.9813528466296535, 0.9864226422463989, 0.9555400680101171, 0.8551365938212034, 0.0555283502481301, 0.09995103044663417, 0.349239158397976, 0.49746275469479134, 0.15431497696654753, 0.5290895013749709, 0.12484134302106055, 0.3477723127015258, 0.8531368871212899, 0.05612742678429539, 0.08980388285487262, 0.9758989780057179, 0.1556362618681733, 0.5238488814099491, 0.3188645365104038, 0.21558456934174083, 0.5798481520226132, 0.20071666800782767, 0.9875472961174302, 0.00753852897799565, 0.00753852897799565, 0.026552939044526117, 0.010621175617810447, 0.9612163934118454, 0.8926682997544098, 0.0726590476544287, 0.034599546502108905, 0.8770857747357608, 0.10081445686617939, 0.02016289137323588, 0.932108817448289, 0.06258102338316766, 0.938715350747515, 0.06258102338316766, 0.1734822892278793, 0.6939291569115172, 0.12677551905114257, 0.9425295027892127, 0.9821986795882813, 0.05139655433385804, 0.34286911904297407, 0.6059383247781159, 0.9754747436002806, 0.9390291637731151, 0.038722852114355256, 0.019361426057177628, 0.9619899898690311, 0.9315999194275866, 0.9350362007313715, 0.5048843601532021, 0.24008487056236183, 0.25773816986841785, 0.9046943769839464, 0.4638245814650783, 0.23285887151103932, 0.30479901067705145, 0.0819446315487643, 0.15218288716199085, 0.7609144358099542, 0.9534553851500511, 0.9425756299564869, 0.15799105095934635, 0.7109597293170585, 0.13542090082229685, 0.6325107099352086, 0.13602380858821692, 0.23124047459996877, 0.9792147061702565, 0.016052700101151746, 0.016052700101151746, 0.9734857662210554, 0.40000588404636195, 0.09438341084240001, 0.5078726392948191, 0.9499227670983801, 0.040710975732787716, 0.013570325244262571, 0.39031249301554244, 0.2764713492193426, 0.33610242454116157, 0.2898152296795746, 0.05914596524072952, 0.6565202141720977, 0.4565288783721316, 0.2274958720507592, 0.3151125254757137, 0.9547397226550882, 0.9067092096127185, 0.016514493755413306, 0.974355131569385], \"Term\": [\"age\", \"age\", \"age\", \"alarm\", \"alexa\", \"alexa\", \"alexa\", \"amazon\", \"amazon\", \"amazon\", \"android\", \"android\", \"android\", \"answer\", \"answer\", \"answer\", \"app\", \"app\", \"app\", \"appear\", \"appear\", \"appear\", \"appropri\", \"arlo\", \"ask\", \"ask\", \"ask\", \"audibl\", \"autom\", \"bad\", \"bad\", \"bad\", \"batteri\", \"batteri\", \"batteri\", \"bedroom\", \"best\", \"best\", \"best\", \"better\", \"better\", \"better\", \"biggest\", \"birthday\", \"birthday\", \"book\", \"book\", \"book\", \"bottom\", \"bought\", \"bought\", \"bought\", \"boy\", \"brief\", \"broke\", \"browser\", \"bulb\", \"bulb\", \"button\", \"button\", \"button\", \"buy\", \"buy\", \"buy\", \"cam\", \"cell\", \"charg\", \"charg\", \"charg\", \"charger\", \"charger\", \"charger\", \"children\", \"children\", \"children\", \"christma\", \"christma\", \"christma\", \"clariti\", \"comfort\", \"comfort\", \"command\", \"command\", \"connect\", \"connect\", \"connect\", \"cook\", \"cover\", \"cover\", \"cover\", \"crack\", \"curiou\", \"daughter\", \"daughter\", \"daughter\", \"devic\", \"devic\", \"devic\", \"dont\", \"dont\", \"dont\", \"doorbel\", \"dot\", \"dot\", \"dot\", \"download\", \"download\", \"download\", \"drain\", \"durabl\", \"durabl\", \"durabl\", \"ebook\", \"ebook\", \"ebook\", \"echo\", \"echo\", \"echo\", \"edg\", \"educ\", \"educ\", \"educ\", \"eread\", \"eread\", \"eread\", \"famili\", \"famili\", \"famili\", \"father\", \"fire\", \"fire\", \"fire\", \"fit\", \"fit\", \"fit\", \"font\", \"four\", \"friendli\", \"friendli\", \"friendli\", \"fun\", \"fun\", \"fun\", \"game\", \"game\", \"game\", \"gift\", \"gift\", \"gift\", \"got\", \"got\", \"got\", \"grand\", \"granddaught\", \"granddaught\", \"granddaught\", \"grandson\", \"grandson\", \"grandson\", \"great\", \"great\", \"great\", \"hand\", \"hand\", \"hand\", \"he\", \"hold\", \"hold\", \"hold\", \"home\", \"home\", \"home\", \"hous\", \"hous\", \"hous\", \"hub\", \"hue\", \"hue\", \"hue\", \"im\", \"im\", \"im\", \"imag\", \"inexpens\", \"inexpens\", \"ipad\", \"ipad\", \"ipad\", \"junk\", \"keyboard\", \"kid\", \"kid\", \"kid\", \"kindl\", \"kindl\", \"kindl\", \"kitchen\", \"law\", \"learn\", \"learn\", \"learn\", \"left\", \"life\", \"life\", \"life\", \"light\", \"light\", \"light\", \"lighter\", \"lighter\", \"lighter\", \"list\", \"list\", \"list\", \"listen\", \"listen\", \"listen\", \"littl\", \"littl\", \"littl\", \"look\", \"look\", \"look\", \"love\", \"love\", \"love\", \"lyric\", \"magazin\", \"magazin\", \"menu\", \"model\", \"model\", \"model\", \"mom\", \"mom\", \"mom\", \"morn\", \"mother\", \"mother\", \"mother\", \"movi\", \"movi\", \"movi\", \"much\", \"much\", \"much\", \"music\", \"music\", \"music\", \"nephew\", \"nephew\", \"nephew\", \"nexu\", \"niec\", \"oasi\", \"oasi\", \"often\", \"often\", \"ok\", \"ok\", \"ok\", \"old\", \"old\", \"old\", \"one\", \"one\", \"one\", \"os\", \"os\", \"os\", \"page\", \"page\", \"page\", \"pandora\", \"paperwhit\", \"paperwhit\", \"paperwhit\", \"parent\", \"parent\", \"parent\", \"perfect\", \"perfect\", \"perfect\", \"philip\", \"phillip\", \"pink\", \"play\", \"play\", \"play\", \"plu\", \"plu\", \"plu\", \"pocket\", \"present\", \"present\", \"present\", \"price\", \"price\", \"price\", \"prior\", \"product\", \"product\", \"product\", \"protect\", \"protect\", \"protect\", \"purchas\", \"purchas\", \"purchas\", \"purs\", \"purs\", \"purs\", \"question\", \"question\", \"question\", \"read\", \"read\", \"read\", \"reader\", \"reader\", \"reader\", \"realli\", \"realli\", \"realli\", \"recip\", \"recipi\", \"ring\", \"room\", \"room\", \"room\", \"screen\", \"screen\", \"screen\", \"set\", \"set\", \"set\", \"show\", \"show\", \"show\", \"silk\", \"size\", \"size\", \"size\", \"small\", \"small\", \"small\", \"smart\", \"smart\", \"smart\", \"son\", \"son\", \"son\", \"sound\", \"sound\", \"sound\", \"speaker\", \"speaker\", \"speaker\", \"spec\", \"spent\", \"spent\", \"spent\", \"store\", \"store\", \"store\", \"sunlight\", \"swipe\", \"tablet\", \"tablet\", \"tablet\", \"tag\", \"tap\", \"tap\", \"tap\", \"teach\", \"teenag\", \"thermostat\", \"thing\", \"thing\", \"thing\", \"tough\", \"use\", \"use\", \"use\", \"user\", \"user\", \"user\", \"variou\", \"versatil\", \"version\", \"version\", \"version\", \"video\", \"video\", \"video\", \"voic\", \"voic\", \"voic\", \"voyag\", \"watch\", \"watch\", \"watch\", \"weather\", \"weather\", \"weather\", \"well\", \"well\", \"well\", \"wife\", \"wife\", \"wife\", \"work\", \"work\", \"work\", \"young\", \"youngest\", \"yr\", \"yr\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 3, 2]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el731406510182510884166399535\", ldavis_el731406510182510884166399535_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el731406510182510884166399535\", ldavis_el731406510182510884166399535_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el731406510182510884166399535\", ldavis_el731406510182510884166399535_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_TUfAo4j6biH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}